{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Dependencies to Visualize the model\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Filepaths, numpy, and Tensorflow\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Sklearn scaling\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Keras\n",
    "from keras.models import Sequential\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading and Preprocessing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['BeerID', 'Name', 'Style', 'StyleID', 'OG', 'FG', 'ABV', 'IBU', 'Color',\n",
      "       'BoilSize', 'BoilTime', 'Efficiency', 'ViewCount', 'BrewCount',\n",
      "       'LastUpdated', 'Category', 'clusters_7param', 'clusters_3param'],\n",
      "      dtype='object')\n",
      "(73861, 3) (73861,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    45\n",
       "1    45\n",
       "2    45\n",
       "3    45\n",
       "4    45\n",
       "Name: StyleID, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import data from Ethan\n",
    "all_beer_df = pd.read_csv(\"data_add_3param_cluster.csv\", encoding=\"latin1\" )\n",
    "\n",
    "#trim data to needed X colums\n",
    "print(all_beer_df.columns)\n",
    "beer_char = all_beer_df[[\"ABV\",\"IBU\",\"Color\"]]\n",
    "\n",
    "#Set beer_char as X \n",
    "X=beer_char\n",
    "X.head()\n",
    "\n",
    "#set y data\n",
    "y=all_beer_df[\"StyleID\"]\n",
    "print(X.shape, y.shape)\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "176\n"
     ]
    }
   ],
   "source": [
    "#find the number of unique beer styles and set as variable\n",
    "\n",
    "#create an array of unique values from the output dataset\n",
    "style_array = pd.unique(y.values)\n",
    "\n",
    "#set the count as the length of the output array\n",
    "style_count = len(style_array)\n",
    "\n",
    "print(style_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###Scale and pre-process the data\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1, stratify=y)\n",
    "X_scaler = StandardScaler().fit(X_train)\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)\n",
    "\n",
    "\n",
    "# Step 1: Label-encode data set\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(y_train)\n",
    "encoded_y_train = label_encoder.transform(y_train)\n",
    "encoded_y_test = label_encoder.transform(y_test)\n",
    "\n",
    "# Step 2: Convert encoded labels to one-hot-encoding\n",
    "y_train_categorical = to_categorical(encoded_y_train)\n",
    "y_test_categorical = to_categorical(encoded_y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n"
     ]
    }
   ],
   "source": [
    "#check the categorical results\n",
    "print(y_train_categorical[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Deep Learning Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#setup a sequential model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "model = Sequential()\n",
    "# Add the first layer where the input dimensions are the 5 inputs (don't have to specify batch size)\n",
    "# We can also choose our activation function. `relu` is a common\n",
    "model.add(Dense(units=300, activation='relu', input_dim=X_train.shape[1]))\n",
    "\n",
    "#add a second hidden layer\n",
    "model.add(Dense(units=300, activation='relu'))\n",
    "\n",
    "#add a second hidden layer\n",
    "model.add(Dense(units=300, activation='relu'))\n",
    "\n",
    "#add a third hidden layer\n",
    "model.add(Dense(units=300, activation='relu'))\n",
    "\n",
    "#specify the output\n",
    "model.add(Dense(units=style_count, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/600\n",
      " - 27s - loss: 2.9502 - acc: 0.2937\n",
      "Epoch 2/600\n",
      " - 26s - loss: 2.7442 - acc: 0.3194\n",
      "Epoch 3/600\n",
      " - 25s - loss: 2.7062 - acc: 0.3222\n",
      "Epoch 4/600\n",
      " - 27s - loss: 2.6835 - acc: 0.3272\n",
      "Epoch 5/600\n",
      " - 26s - loss: 2.6653 - acc: 0.3286\n",
      "Epoch 6/600\n",
      " - 25s - loss: 2.6509 - acc: 0.3308\n",
      "Epoch 7/600\n",
      " - 26s - loss: 2.6384 - acc: 0.3326\n",
      "Epoch 8/600\n",
      " - 27s - loss: 2.6288 - acc: 0.3323\n",
      "Epoch 9/600\n",
      " - 29s - loss: 2.6177 - acc: 0.3344\n",
      "Epoch 10/600\n",
      " - 28s - loss: 2.6088 - acc: 0.3347\n",
      "Epoch 11/600\n",
      " - 28s - loss: 2.5998 - acc: 0.3367\n",
      "Epoch 12/600\n",
      " - 29s - loss: 2.5932 - acc: 0.3355\n",
      "Epoch 13/600\n",
      " - 28s - loss: 2.5839 - acc: 0.3365\n",
      "Epoch 14/600\n",
      " - 27s - loss: 2.5792 - acc: 0.3365\n",
      "Epoch 15/600\n",
      " - 25s - loss: 2.5723 - acc: 0.3374\n",
      "Epoch 16/600\n",
      " - 25s - loss: 2.5660 - acc: 0.3389\n",
      "Epoch 17/600\n",
      " - 25s - loss: 2.5605 - acc: 0.3389\n",
      "Epoch 18/600\n",
      " - 25s - loss: 2.5540 - acc: 0.3397\n",
      "Epoch 19/600\n",
      " - 25s - loss: 2.5476 - acc: 0.3397\n",
      "Epoch 20/600\n",
      " - 25s - loss: 2.5404 - acc: 0.3404\n",
      "Epoch 21/600\n",
      " - 26s - loss: 2.5356 - acc: 0.3410\n",
      "Epoch 22/600\n",
      " - 26s - loss: 2.5325 - acc: 0.3411\n",
      "Epoch 23/600\n",
      " - 26s - loss: 2.5258 - acc: 0.3414\n",
      "Epoch 24/600\n",
      " - 25s - loss: 2.5191 - acc: 0.3423\n",
      "Epoch 25/600\n",
      " - 26s - loss: 2.5147 - acc: 0.3434\n",
      "Epoch 26/600\n",
      " - 26s - loss: 2.5113 - acc: 0.3417\n",
      "Epoch 27/600\n",
      " - 26s - loss: 2.5042 - acc: 0.3432\n",
      "Epoch 28/600\n",
      " - 26s - loss: 2.4995 - acc: 0.3441\n",
      "Epoch 29/600\n",
      " - 26s - loss: 2.4957 - acc: 0.3437\n",
      "Epoch 30/600\n",
      " - 26s - loss: 2.4897 - acc: 0.3450\n",
      "Epoch 31/600\n",
      " - 26s - loss: 2.4841 - acc: 0.3450\n",
      "Epoch 32/600\n",
      " - 26s - loss: 2.4785 - acc: 0.3465\n",
      "Epoch 33/600\n",
      " - 25s - loss: 2.4756 - acc: 0.3458\n",
      "Epoch 34/600\n",
      " - 25s - loss: 2.4698 - acc: 0.3469\n",
      "Epoch 35/600\n",
      " - 26s - loss: 2.4656 - acc: 0.3450\n",
      "Epoch 36/600\n",
      " - 25s - loss: 2.4613 - acc: 0.3450\n",
      "Epoch 37/600\n",
      " - 26s - loss: 2.4560 - acc: 0.3480\n",
      "Epoch 38/600\n",
      " - 26s - loss: 2.4526 - acc: 0.3472\n",
      "Epoch 39/600\n",
      " - 26s - loss: 2.4464 - acc: 0.3469\n",
      "Epoch 40/600\n",
      " - 25s - loss: 2.4425 - acc: 0.3490\n",
      "Epoch 41/600\n",
      " - 26s - loss: 2.4376 - acc: 0.3486\n",
      "Epoch 42/600\n",
      " - 25s - loss: 2.4323 - acc: 0.3488\n",
      "Epoch 43/600\n",
      " - 26s - loss: 2.4325 - acc: 0.3487\n",
      "Epoch 44/600\n",
      " - 25s - loss: 2.4250 - acc: 0.3486\n",
      "Epoch 45/600\n",
      " - 25s - loss: 2.4207 - acc: 0.3486\n",
      "Epoch 46/600\n",
      " - 26s - loss: 2.4161 - acc: 0.3503\n",
      "Epoch 47/600\n",
      " - 26s - loss: 2.4127 - acc: 0.3500\n",
      "Epoch 48/600\n",
      " - 26s - loss: 2.4104 - acc: 0.3501\n",
      "Epoch 49/600\n",
      " - 25s - loss: 2.4048 - acc: 0.3504\n",
      "Epoch 50/600\n",
      " - 26s - loss: 2.3983 - acc: 0.3512\n",
      "Epoch 51/600\n",
      " - 26s - loss: 2.3962 - acc: 0.3508\n",
      "Epoch 52/600\n",
      " - 25s - loss: 2.3921 - acc: 0.3513\n",
      "Epoch 53/600\n",
      " - 25s - loss: 2.3863 - acc: 0.3528\n",
      "Epoch 54/600\n",
      " - 26s - loss: 2.3821 - acc: 0.3521\n",
      "Epoch 55/600\n",
      " - 26s - loss: 2.3785 - acc: 0.3523\n",
      "Epoch 56/600\n",
      " - 25s - loss: 2.3766 - acc: 0.3520\n",
      "Epoch 57/600\n",
      " - 26s - loss: 2.3700 - acc: 0.3536\n",
      "Epoch 58/600\n",
      " - 25s - loss: 2.3667 - acc: 0.3541\n",
      "Epoch 59/600\n",
      " - 26s - loss: 2.3636 - acc: 0.3545\n",
      "Epoch 60/600\n",
      " - 25s - loss: 2.3605 - acc: 0.3541\n",
      "Epoch 61/600\n",
      " - 26s - loss: 2.3563 - acc: 0.3543\n",
      "Epoch 62/600\n",
      " - 26s - loss: 2.3509 - acc: 0.3550\n",
      "Epoch 63/600\n",
      " - 25s - loss: 2.3510 - acc: 0.3546\n",
      "Epoch 64/600\n",
      " - 26s - loss: 2.3470 - acc: 0.3560\n",
      "Epoch 65/600\n",
      " - 25s - loss: 2.3398 - acc: 0.3556\n",
      "Epoch 66/600\n",
      " - 25s - loss: 2.3363 - acc: 0.3566\n",
      "Epoch 67/600\n",
      " - 25s - loss: 2.3360 - acc: 0.3565\n",
      "Epoch 68/600\n",
      " - 25s - loss: 2.3303 - acc: 0.3562\n",
      "Epoch 69/600\n",
      " - 26s - loss: 2.3301 - acc: 0.3565\n",
      "Epoch 70/600\n",
      " - 26s - loss: 2.3243 - acc: 0.3571\n",
      "Epoch 71/600\n",
      " - 26s - loss: 2.3201 - acc: 0.3563\n",
      "Epoch 72/600\n",
      " - 25s - loss: 2.3176 - acc: 0.3574\n",
      "Epoch 73/600\n",
      " - 25s - loss: 2.3167 - acc: 0.3567\n",
      "Epoch 74/600\n",
      " - 26s - loss: 2.3092 - acc: 0.3582\n",
      "Epoch 75/600\n",
      " - 26s - loss: 2.3076 - acc: 0.3588\n",
      "Epoch 76/600\n",
      " - 25s - loss: 2.3056 - acc: 0.3584\n",
      "Epoch 77/600\n",
      " - 26s - loss: 2.3040 - acc: 0.3572\n",
      "Epoch 78/600\n",
      " - 25s - loss: 2.2966 - acc: 0.3594\n",
      "Epoch 79/600\n",
      " - 25s - loss: 2.2963 - acc: 0.3594\n",
      "Epoch 80/600\n",
      " - 25s - loss: 2.2941 - acc: 0.3600\n",
      "Epoch 81/600\n",
      " - 26s - loss: 2.2898 - acc: 0.3586\n",
      "Epoch 82/600\n",
      " - 26s - loss: 2.2878 - acc: 0.3598\n",
      "Epoch 83/600\n",
      " - 26s - loss: 2.2826 - acc: 0.3608\n",
      "Epoch 84/600\n",
      " - 26s - loss: 2.2814 - acc: 0.3606\n",
      "Epoch 85/600\n",
      " - 26s - loss: 2.2788 - acc: 0.3623\n",
      "Epoch 86/600\n",
      " - 25s - loss: 2.2726 - acc: 0.3608\n",
      "Epoch 87/600\n",
      " - 26s - loss: 2.2720 - acc: 0.3609\n",
      "Epoch 88/600\n",
      " - 26s - loss: 2.2670 - acc: 0.3623\n",
      "Epoch 89/600\n",
      " - 26s - loss: 2.2647 - acc: 0.3626\n",
      "Epoch 90/600\n",
      " - 25s - loss: 2.2605 - acc: 0.3634\n",
      "Epoch 91/600\n",
      " - 25s - loss: 2.2621 - acc: 0.3628\n",
      "Epoch 92/600\n",
      " - 25s - loss: 2.2585 - acc: 0.3628\n",
      "Epoch 93/600\n",
      " - 25s - loss: 2.2554 - acc: 0.3628\n",
      "Epoch 94/600\n",
      " - 26s - loss: 2.2529 - acc: 0.3621\n",
      "Epoch 95/600\n",
      " - 25s - loss: 2.2493 - acc: 0.3627\n",
      "Epoch 96/600\n",
      " - 26s - loss: 2.2452 - acc: 0.3642\n",
      "Epoch 97/600\n",
      " - 26s - loss: 2.2443 - acc: 0.3638\n",
      "Epoch 98/600\n",
      " - 25s - loss: 2.2403 - acc: 0.3643\n",
      "Epoch 99/600\n",
      " - 25s - loss: 2.2379 - acc: 0.3634\n",
      "Epoch 100/600\n",
      " - 26s - loss: 2.2338 - acc: 0.3637\n",
      "Epoch 101/600\n",
      " - 25s - loss: 2.2355 - acc: 0.3663\n",
      "Epoch 102/600\n",
      " - 26s - loss: 2.2297 - acc: 0.3664\n",
      "Epoch 103/600\n",
      " - 25s - loss: 2.2304 - acc: 0.3633\n",
      "Epoch 104/600\n",
      " - 25s - loss: 2.2263 - acc: 0.3652\n",
      "Epoch 105/600\n",
      " - 25s - loss: 2.2215 - acc: 0.3661\n",
      "Epoch 106/600\n",
      " - 26s - loss: 2.2242 - acc: 0.3649\n",
      "Epoch 107/600\n",
      " - 26s - loss: 2.2170 - acc: 0.3665\n",
      "Epoch 108/600\n",
      " - 25s - loss: 2.2194 - acc: 0.3660\n",
      "Epoch 109/600\n",
      " - 25s - loss: 2.2155 - acc: 0.3682\n",
      "Epoch 110/600\n",
      " - 25s - loss: 2.2126 - acc: 0.3649\n",
      "Epoch 111/600\n",
      " - 26s - loss: 2.2083 - acc: 0.3674\n",
      "Epoch 112/600\n",
      " - 25s - loss: 2.2055 - acc: 0.3665\n",
      "Epoch 113/600\n",
      " - 25s - loss: 2.2056 - acc: 0.3662\n",
      "Epoch 114/600\n",
      " - 25s - loss: 2.2059 - acc: 0.3675\n",
      "Epoch 115/600\n",
      " - 26s - loss: 2.2011 - acc: 0.3677\n",
      "Epoch 116/600\n",
      " - 26s - loss: 2.2027 - acc: 0.3669\n",
      "Epoch 117/600\n",
      " - 26s - loss: 2.1951 - acc: 0.3679\n",
      "Epoch 118/600\n",
      " - 25s - loss: 2.1937 - acc: 0.3681\n",
      "Epoch 119/600\n",
      " - 25s - loss: 2.1940 - acc: 0.3673\n",
      "Epoch 120/600\n",
      " - 25s - loss: 2.1939 - acc: 0.3674\n",
      "Epoch 121/600\n",
      " - 24s - loss: 2.1889 - acc: 0.3682\n",
      "Epoch 122/600\n",
      " - 24s - loss: 2.1870 - acc: 0.3687\n",
      "Epoch 123/600\n",
      " - 24s - loss: 2.1863 - acc: 0.3692\n",
      "Epoch 124/600\n",
      " - 24s - loss: 2.1822 - acc: 0.3705\n",
      "Epoch 125/600\n",
      " - 24s - loss: 2.1821 - acc: 0.3702\n",
      "Epoch 126/600\n",
      " - 24s - loss: 2.1764 - acc: 0.3709\n",
      "Epoch 127/600\n",
      " - 24s - loss: 2.1767 - acc: 0.3694\n",
      "Epoch 128/600\n",
      " - 24s - loss: 2.1732 - acc: 0.3694\n",
      "Epoch 129/600\n",
      " - 24s - loss: 2.1754 - acc: 0.3714\n",
      "Epoch 130/600\n",
      " - 24s - loss: 2.1661 - acc: 0.3712\n",
      "Epoch 131/600\n",
      " - 24s - loss: 2.1690 - acc: 0.3702\n",
      "Epoch 132/600\n",
      " - 24s - loss: 2.1697 - acc: 0.3717\n",
      "Epoch 133/600\n",
      " - 24s - loss: 2.1631 - acc: 0.3716\n",
      "Epoch 134/600\n",
      " - 24s - loss: 2.1650 - acc: 0.3716\n",
      "Epoch 135/600\n",
      " - 24s - loss: 2.1603 - acc: 0.3731\n",
      "Epoch 136/600\n",
      " - 24s - loss: 2.1622 - acc: 0.3724\n",
      "Epoch 137/600\n",
      " - 24s - loss: 2.1537 - acc: 0.3738\n",
      "Epoch 138/600\n",
      " - 24s - loss: 2.1621 - acc: 0.3721\n",
      "Epoch 139/600\n",
      " - 24s - loss: 2.1584 - acc: 0.3734\n",
      "Epoch 140/600\n",
      " - 24s - loss: 2.1476 - acc: 0.3739\n",
      "Epoch 141/600\n",
      " - 24s - loss: 2.1520 - acc: 0.3738\n",
      "Epoch 142/600\n",
      " - 24s - loss: 2.1485 - acc: 0.3737\n",
      "Epoch 143/600\n",
      " - 24s - loss: 2.1491 - acc: 0.3732\n",
      "Epoch 144/600\n",
      " - 24s - loss: 2.1439 - acc: 0.3734\n",
      "Epoch 145/600\n",
      " - 24s - loss: 2.1448 - acc: 0.3725\n",
      "Epoch 146/600\n",
      " - 24s - loss: 2.1424 - acc: 0.3743\n",
      "Epoch 147/600\n",
      " - 24s - loss: 2.1388 - acc: 0.3751\n",
      "Epoch 148/600\n",
      " - 24s - loss: 2.1355 - acc: 0.3756\n",
      "Epoch 149/600\n",
      " - 24s - loss: 2.1402 - acc: 0.3748\n",
      "Epoch 150/600\n",
      " - 24s - loss: 2.1355 - acc: 0.3743\n",
      "Epoch 151/600\n",
      " - 24s - loss: 2.1357 - acc: 0.3760\n",
      "Epoch 152/600\n",
      " - 24s - loss: 2.1359 - acc: 0.3739\n",
      "Epoch 153/600\n",
      " - 24s - loss: 2.1299 - acc: 0.3749\n",
      "Epoch 154/600\n",
      " - 24s - loss: 2.1333 - acc: 0.3756\n",
      "Epoch 155/600\n",
      " - 24s - loss: 2.1292 - acc: 0.3768\n",
      "Epoch 156/600\n",
      " - 24s - loss: 2.1282 - acc: 0.3743\n",
      "Epoch 157/600\n",
      " - 24s - loss: 2.1260 - acc: 0.3733\n",
      "Epoch 158/600\n",
      " - 24s - loss: 2.1255 - acc: 0.3760\n",
      "Epoch 159/600\n",
      " - 24s - loss: 2.1230 - acc: 0.3767\n",
      "Epoch 160/600\n",
      " - 24s - loss: 2.1199 - acc: 0.3774\n",
      "Epoch 161/600\n",
      " - 24s - loss: 2.1173 - acc: 0.3787\n",
      "Epoch 162/600\n",
      " - 24s - loss: 2.1194 - acc: 0.3763\n",
      "Epoch 163/600\n",
      " - 24s - loss: 2.1167 - acc: 0.3783\n",
      "Epoch 164/600\n",
      " - 24s - loss: 2.1208 - acc: 0.3763\n",
      "Epoch 165/600\n",
      " - 24s - loss: 2.1131 - acc: 0.3765\n",
      "Epoch 166/600\n",
      " - 24s - loss: 2.1146 - acc: 0.3801\n",
      "Epoch 167/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 24s - loss: 2.1160 - acc: 0.3754\n",
      "Epoch 168/600\n",
      " - 24s - loss: 2.1119 - acc: 0.3776\n",
      "Epoch 169/600\n",
      " - 24s - loss: 2.1074 - acc: 0.3775\n",
      "Epoch 170/600\n",
      " - 24s - loss: 2.1064 - acc: 0.3771\n",
      "Epoch 171/600\n",
      " - 24s - loss: 2.1106 - acc: 0.3782\n",
      "Epoch 172/600\n",
      " - 24s - loss: 2.1062 - acc: 0.3786\n",
      "Epoch 173/600\n",
      " - 24s - loss: 2.0998 - acc: 0.3791\n",
      "Epoch 174/600\n",
      " - 24s - loss: 2.1059 - acc: 0.3800\n",
      "Epoch 175/600\n",
      " - 24s - loss: 2.1028 - acc: 0.3797\n",
      "Epoch 176/600\n",
      " - 24s - loss: 2.0975 - acc: 0.3788\n",
      "Epoch 177/600\n",
      " - 24s - loss: 2.0986 - acc: 0.3803\n",
      "Epoch 178/600\n",
      " - 24s - loss: 2.0956 - acc: 0.3805\n",
      "Epoch 179/600\n",
      " - 24s - loss: 2.1021 - acc: 0.3810\n",
      "Epoch 180/600\n",
      " - 26s - loss: 2.0947 - acc: 0.3799\n",
      "Epoch 181/600\n",
      " - 26s - loss: 2.0897 - acc: 0.3803\n",
      "Epoch 182/600\n",
      " - 25s - loss: 2.0901 - acc: 0.3798\n",
      "Epoch 183/600\n",
      " - 26s - loss: 2.0963 - acc: 0.3797\n",
      "Epoch 184/600\n",
      " - 26s - loss: 2.0891 - acc: 0.3816\n",
      "Epoch 185/600\n",
      " - 25s - loss: 2.0818 - acc: 0.3812\n",
      "Epoch 186/600\n",
      " - 25s - loss: 2.0870 - acc: 0.3817\n",
      "Epoch 187/600\n",
      " - 25s - loss: 2.0873 - acc: 0.3814\n",
      "Epoch 188/600\n",
      " - 25s - loss: 2.0862 - acc: 0.3817\n",
      "Epoch 189/600\n",
      " - 25s - loss: 2.0841 - acc: 0.3810\n",
      "Epoch 190/600\n",
      " - 26s - loss: 2.0845 - acc: 0.3826\n",
      "Epoch 191/600\n",
      " - 26s - loss: 2.0874 - acc: 0.3811\n",
      "Epoch 192/600\n",
      " - 26s - loss: 2.0803 - acc: 0.3809\n",
      "Epoch 193/600\n",
      " - 25s - loss: 2.0799 - acc: 0.3799\n",
      "Epoch 194/600\n",
      " - 25s - loss: 2.0758 - acc: 0.3822\n",
      "Epoch 195/600\n",
      " - 25s - loss: 2.0785 - acc: 0.3820\n",
      "Epoch 196/600\n",
      " - 25s - loss: 2.0786 - acc: 0.3832\n",
      "Epoch 197/600\n",
      " - 26s - loss: 2.0795 - acc: 0.3786\n",
      "Epoch 198/600\n",
      " - 25s - loss: 2.0714 - acc: 0.3822\n",
      "Epoch 199/600\n",
      " - 25s - loss: 2.0717 - acc: 0.3842\n",
      "Epoch 200/600\n",
      " - 25s - loss: 2.0681 - acc: 0.3828\n",
      "Epoch 201/600\n",
      " - 26s - loss: 2.0725 - acc: 0.3813\n",
      "Epoch 202/600\n",
      " - 26s - loss: 2.0708 - acc: 0.3853\n",
      "Epoch 203/600\n",
      " - 26s - loss: 2.0727 - acc: 0.3832\n",
      "Epoch 204/600\n",
      " - 25s - loss: 2.0686 - acc: 0.3815\n",
      "Epoch 205/600\n",
      " - 25s - loss: 2.0681 - acc: 0.3832\n",
      "Epoch 206/600\n",
      " - 25s - loss: 2.0633 - acc: 0.3828\n",
      "Epoch 207/600\n",
      " - 25s - loss: 2.0706 - acc: 0.3827\n",
      "Epoch 208/600\n",
      " - 25s - loss: 2.0679 - acc: 0.3839\n",
      "Epoch 209/600\n",
      " - 26s - loss: 2.0640 - acc: 0.3834\n",
      "Epoch 210/600\n",
      " - 25s - loss: 2.0612 - acc: 0.3845\n",
      "Epoch 211/600\n",
      " - 25s - loss: 2.0668 - acc: 0.3825\n",
      "Epoch 212/600\n",
      " - 25s - loss: 2.0566 - acc: 0.3839\n",
      "Epoch 213/600\n",
      " - 25s - loss: 2.0598 - acc: 0.3839\n",
      "Epoch 214/600\n",
      " - 26s - loss: 2.0603 - acc: 0.3839\n",
      "Epoch 215/600\n",
      " - 26s - loss: 2.0532 - acc: 0.3863\n",
      "Epoch 216/600\n",
      " - 25s - loss: 2.0627 - acc: 0.3841\n",
      "Epoch 217/600\n",
      " - 25s - loss: 2.0604 - acc: 0.3855\n",
      "Epoch 218/600\n",
      " - 25s - loss: 2.0535 - acc: 0.3859\n",
      "Epoch 219/600\n",
      " - 26s - loss: 2.0496 - acc: 0.3852\n",
      "Epoch 220/600\n",
      " - 25s - loss: 2.0577 - acc: 0.3861\n",
      "Epoch 221/600\n",
      " - 26s - loss: 2.0517 - acc: 0.3856\n",
      "Epoch 222/600\n",
      " - 25s - loss: 2.0532 - acc: 0.3855\n",
      "Epoch 223/600\n",
      " - 25s - loss: 2.0571 - acc: 0.3876\n",
      "Epoch 224/600\n",
      " - 26s - loss: 2.0561 - acc: 0.3852\n",
      "Epoch 225/600\n",
      " - 26s - loss: 2.0457 - acc: 0.3876\n",
      "Epoch 226/600\n",
      " - 25s - loss: 2.0534 - acc: 0.3855\n",
      "Epoch 227/600\n",
      " - 26s - loss: 2.0470 - acc: 0.3856\n",
      "Epoch 228/600\n",
      " - 25s - loss: 2.0604 - acc: 0.3835\n",
      "Epoch 229/600\n",
      " - 25s - loss: 2.0504 - acc: 0.3853\n",
      "Epoch 230/600\n",
      " - 24s - loss: 2.0454 - acc: 0.3862\n",
      "Epoch 231/600\n",
      " - 24s - loss: 2.0478 - acc: 0.3874\n",
      "Epoch 232/600\n",
      " - 24s - loss: 2.0551 - acc: 0.3857\n",
      "Epoch 233/600\n",
      " - 24s - loss: 2.0487 - acc: 0.3876\n",
      "Epoch 234/600\n",
      " - 24s - loss: 2.0420 - acc: 0.3857\n",
      "Epoch 235/600\n",
      " - 24s - loss: 2.0372 - acc: 0.3893\n",
      "Epoch 236/600\n",
      " - 24s - loss: 2.0414 - acc: 0.3848\n",
      "Epoch 237/600\n",
      " - 24s - loss: 2.0401 - acc: 0.3864\n",
      "Epoch 238/600\n",
      " - 24s - loss: 2.0424 - acc: 0.3856\n",
      "Epoch 239/600\n",
      " - 24s - loss: 2.0437 - acc: 0.3866\n",
      "Epoch 240/600\n",
      " - 24s - loss: 2.0328 - acc: 0.3854\n",
      "Epoch 241/600\n",
      " - 24s - loss: 2.0324 - acc: 0.3885\n",
      "Epoch 242/600\n",
      " - 24s - loss: 2.0432 - acc: 0.3875\n",
      "Epoch 243/600\n",
      " - 24s - loss: 2.0415 - acc: 0.3887\n",
      "Epoch 244/600\n",
      " - 24s - loss: 2.0331 - acc: 0.3888\n",
      "Epoch 245/600\n",
      " - 24s - loss: 2.0388 - acc: 0.3877\n",
      "Epoch 246/600\n",
      " - 24s - loss: 2.0318 - acc: 0.3885\n",
      "Epoch 247/600\n",
      " - 24s - loss: 2.0308 - acc: 0.3908\n",
      "Epoch 248/600\n",
      " - 24s - loss: 2.0316 - acc: 0.3865\n",
      "Epoch 249/600\n",
      " - 24s - loss: 2.0272 - acc: 0.3903\n",
      "Epoch 250/600\n",
      " - 24s - loss: 2.0339 - acc: 0.3879\n",
      "Epoch 251/600\n",
      " - 24s - loss: 2.0330 - acc: 0.3873\n",
      "Epoch 252/600\n",
      " - 24s - loss: 2.0307 - acc: 0.3880\n",
      "Epoch 253/600\n",
      " - 24s - loss: 2.0298 - acc: 0.3893\n",
      "Epoch 254/600\n",
      " - 24s - loss: 2.0330 - acc: 0.3877\n",
      "Epoch 255/600\n",
      " - 24s - loss: 2.0402 - acc: 0.3866\n",
      "Epoch 256/600\n",
      " - 24s - loss: 2.0340 - acc: 0.3851\n",
      "Epoch 257/600\n",
      " - 24s - loss: 2.0266 - acc: 0.3888\n",
      "Epoch 258/600\n",
      " - 24s - loss: 2.0238 - acc: 0.3896\n",
      "Epoch 259/600\n",
      " - 24s - loss: 2.0252 - acc: 0.3893\n",
      "Epoch 260/600\n",
      " - 24s - loss: 2.0275 - acc: 0.3886\n",
      "Epoch 261/600\n",
      " - 24s - loss: 2.0266 - acc: 0.3901\n",
      "Epoch 262/600\n",
      " - 24s - loss: 2.0274 - acc: 0.3879\n",
      "Epoch 263/600\n",
      " - 24s - loss: 2.0269 - acc: 0.3887\n",
      "Epoch 264/600\n",
      " - 24s - loss: 2.0271 - acc: 0.3906\n",
      "Epoch 265/600\n",
      " - 24s - loss: 2.0240 - acc: 0.3898\n",
      "Epoch 266/600\n",
      " - 24s - loss: 2.0281 - acc: 0.3888\n",
      "Epoch 267/600\n",
      " - 24s - loss: 2.0201 - acc: 0.3914\n",
      "Epoch 268/600\n",
      " - 24s - loss: 2.0271 - acc: 0.3886\n",
      "Epoch 269/600\n",
      " - 24s - loss: 2.0139 - acc: 0.3919\n",
      "Epoch 270/600\n",
      " - 24s - loss: 2.0215 - acc: 0.3900\n",
      "Epoch 271/600\n",
      " - 24s - loss: 2.0195 - acc: 0.3895\n",
      "Epoch 272/600\n",
      " - 24s - loss: 2.0165 - acc: 0.3913\n",
      "Epoch 273/600\n",
      " - 24s - loss: 2.0227 - acc: 0.3897\n",
      "Epoch 274/600\n",
      " - 24s - loss: 2.0214 - acc: 0.3893\n",
      "Epoch 275/600\n",
      " - 24s - loss: 2.0128 - acc: 0.3889\n",
      "Epoch 276/600\n",
      " - 24s - loss: 2.0148 - acc: 0.3919\n",
      "Epoch 277/600\n",
      " - 25s - loss: 2.0228 - acc: 0.3883\n",
      "Epoch 278/600\n",
      " - 24s - loss: 2.0143 - acc: 0.3912\n",
      "Epoch 279/600\n",
      " - 24s - loss: 2.0144 - acc: 0.3918\n",
      "Epoch 280/600\n",
      " - 24s - loss: 2.0154 - acc: 0.3903\n",
      "Epoch 281/600\n",
      " - 24s - loss: 2.0130 - acc: 0.3915\n",
      "Epoch 282/600\n",
      " - 24s - loss: 2.0145 - acc: 0.3904\n",
      "Epoch 283/600\n",
      " - 24s - loss: 2.0123 - acc: 0.3920\n",
      "Epoch 284/600\n",
      " - 24s - loss: 2.0145 - acc: 0.3934\n",
      "Epoch 285/600\n",
      " - 24s - loss: 2.0086 - acc: 0.3917\n",
      "Epoch 286/600\n",
      " - 24s - loss: 2.0210 - acc: 0.3892\n",
      "Epoch 287/600\n",
      " - 24s - loss: 2.0128 - acc: 0.3912\n",
      "Epoch 288/600\n",
      " - 24s - loss: 2.0038 - acc: 0.3914\n",
      "Epoch 289/600\n",
      " - 24s - loss: 2.0156 - acc: 0.3922\n",
      "Epoch 290/600\n",
      " - 24s - loss: 2.0163 - acc: 0.3905\n",
      "Epoch 291/600\n",
      " - 24s - loss: 2.0051 - acc: 0.3925\n",
      "Epoch 292/600\n",
      " - 24s - loss: 2.0080 - acc: 0.3919\n",
      "Epoch 293/600\n",
      " - 24s - loss: 2.0097 - acc: 0.3921\n",
      "Epoch 294/600\n",
      " - 24s - loss: 2.0053 - acc: 0.3923\n",
      "Epoch 295/600\n",
      " - 24s - loss: 2.0034 - acc: 0.3927\n",
      "Epoch 296/600\n",
      " - 24s - loss: 2.0045 - acc: 0.3918\n",
      "Epoch 297/600\n",
      " - 24s - loss: 2.0075 - acc: 0.3916\n",
      "Epoch 298/600\n",
      " - 24s - loss: 2.0053 - acc: 0.3927\n",
      "Epoch 299/600\n",
      " - 24s - loss: 2.0103 - acc: 0.3917\n",
      "Epoch 300/600\n",
      " - 24s - loss: 2.0053 - acc: 0.3913\n",
      "Epoch 301/600\n",
      " - 24s - loss: 2.0062 - acc: 0.3925\n",
      "Epoch 302/600\n",
      " - 24s - loss: 2.0060 - acc: 0.3914\n",
      "Epoch 303/600\n",
      " - 24s - loss: 2.0104 - acc: 0.3923\n",
      "Epoch 304/600\n",
      " - 24s - loss: 2.0067 - acc: 0.3912\n",
      "Epoch 305/600\n",
      " - 24s - loss: 2.0014 - acc: 0.3934\n",
      "Epoch 306/600\n",
      " - 24s - loss: 1.9970 - acc: 0.3923\n",
      "Epoch 307/600\n",
      " - 24s - loss: 1.9983 - acc: 0.3942\n",
      "Epoch 308/600\n",
      " - 24s - loss: 2.0090 - acc: 0.3904\n",
      "Epoch 309/600\n",
      " - 24s - loss: 2.0019 - acc: 0.3944\n",
      "Epoch 310/600\n",
      " - 24s - loss: 2.0016 - acc: 0.3950\n",
      "Epoch 311/600\n",
      " - 24s - loss: 2.0021 - acc: 0.3927\n",
      "Epoch 312/600\n",
      " - 24s - loss: 2.0120 - acc: 0.3881\n",
      "Epoch 313/600\n",
      " - 24s - loss: 1.9990 - acc: 0.3949\n",
      "Epoch 314/600\n",
      " - 24s - loss: 2.0014 - acc: 0.3923\n",
      "Epoch 315/600\n",
      " - 24s - loss: 1.9975 - acc: 0.3947\n",
      "Epoch 316/600\n",
      " - 24s - loss: 2.0063 - acc: 0.3914\n",
      "Epoch 317/600\n",
      " - 24s - loss: 2.0045 - acc: 0.3904\n",
      "Epoch 318/600\n",
      " - 24s - loss: 1.9939 - acc: 0.3949\n",
      "Epoch 319/600\n",
      " - 24s - loss: 2.0020 - acc: 0.3924\n",
      "Epoch 320/600\n",
      " - 24s - loss: 1.9940 - acc: 0.3939\n",
      "Epoch 321/600\n",
      " - 24s - loss: 2.0035 - acc: 0.3923\n",
      "Epoch 322/600\n",
      " - 24s - loss: 2.0058 - acc: 0.3932\n",
      "Epoch 323/600\n",
      " - 24s - loss: 1.9867 - acc: 0.3962\n",
      "Epoch 324/600\n",
      " - 24s - loss: 2.0005 - acc: 0.3934\n",
      "Epoch 325/600\n",
      " - 24s - loss: 2.0024 - acc: 0.3923\n",
      "Epoch 326/600\n",
      " - 24s - loss: 1.9982 - acc: 0.3913\n",
      "Epoch 327/600\n",
      " - 24s - loss: 1.9981 - acc: 0.3932\n",
      "Epoch 328/600\n",
      " - 24s - loss: 1.9943 - acc: 0.3944\n",
      "Epoch 329/600\n",
      " - 24s - loss: 1.9948 - acc: 0.3933\n",
      "Epoch 330/600\n",
      " - 24s - loss: 1.9925 - acc: 0.3944\n",
      "Epoch 331/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 24s - loss: 2.0010 - acc: 0.3925\n",
      "Epoch 332/600\n",
      " - 24s - loss: 2.0017 - acc: 0.3929\n",
      "Epoch 333/600\n",
      " - 24s - loss: 1.9925 - acc: 0.3956\n",
      "Epoch 334/600\n",
      " - 24s - loss: 1.9945 - acc: 0.3929\n",
      "Epoch 335/600\n",
      " - 24s - loss: 2.0095 - acc: 0.3924\n",
      "Epoch 336/600\n",
      " - 24s - loss: 2.0003 - acc: 0.3940\n",
      "Epoch 337/600\n",
      " - 24s - loss: 2.0000 - acc: 0.3942\n",
      "Epoch 338/600\n",
      " - 24s - loss: 1.9977 - acc: 0.3962\n",
      "Epoch 339/600\n",
      " - 24s - loss: 2.0052 - acc: 0.3913\n",
      "Epoch 340/600\n",
      " - 24s - loss: 1.9876 - acc: 0.3981\n",
      "Epoch 341/600\n",
      " - 24s - loss: 2.0015 - acc: 0.3921\n",
      "Epoch 342/600\n",
      " - 24s - loss: 1.9939 - acc: 0.3940\n",
      "Epoch 343/600\n",
      " - 24s - loss: 1.9943 - acc: 0.3936\n",
      "Epoch 344/600\n",
      " - 24s - loss: 1.9972 - acc: 0.3943\n",
      "Epoch 345/600\n",
      " - 24s - loss: 1.9922 - acc: 0.3958\n",
      "Epoch 346/600\n",
      " - 24s - loss: 1.9868 - acc: 0.3974\n",
      "Epoch 347/600\n",
      " - 24s - loss: 1.9901 - acc: 0.3949\n",
      "Epoch 348/600\n",
      " - 24s - loss: 1.9981 - acc: 0.3934\n",
      "Epoch 349/600\n",
      " - 24s - loss: 1.9968 - acc: 0.3941\n",
      "Epoch 350/600\n",
      " - 24s - loss: 1.9808 - acc: 0.3975\n",
      "Epoch 351/600\n",
      " - 24s - loss: 1.9907 - acc: 0.3943\n",
      "Epoch 352/600\n",
      " - 24s - loss: 1.9926 - acc: 0.3960\n",
      "Epoch 353/600\n",
      " - 24s - loss: 1.9875 - acc: 0.3935\n",
      "Epoch 354/600\n",
      " - 24s - loss: 1.9936 - acc: 0.3951\n",
      "Epoch 355/600\n",
      " - 24s - loss: 2.0002 - acc: 0.3939\n",
      "Epoch 356/600\n",
      " - 24s - loss: 1.9902 - acc: 0.3931\n",
      "Epoch 357/600\n",
      " - 24s - loss: 1.9932 - acc: 0.3963\n",
      "Epoch 358/600\n",
      " - 24s - loss: 1.9846 - acc: 0.3938\n",
      "Epoch 359/600\n",
      " - 24s - loss: 1.9930 - acc: 0.3932\n",
      "Epoch 360/600\n",
      " - 24s - loss: 1.9818 - acc: 0.3962\n",
      "Epoch 361/600\n",
      " - 24s - loss: 2.0003 - acc: 0.3962\n",
      "Epoch 362/600\n",
      " - 24s - loss: 1.9877 - acc: 0.3973\n",
      "Epoch 363/600\n",
      " - 24s - loss: 1.9897 - acc: 0.3955\n",
      "Epoch 364/600\n",
      " - 24s - loss: 1.9908 - acc: 0.3939\n",
      "Epoch 365/600\n",
      " - 24s - loss: 1.9861 - acc: 0.3967\n",
      "Epoch 366/600\n",
      " - 24s - loss: 1.9882 - acc: 0.3945\n",
      "Epoch 367/600\n",
      " - 24s - loss: 1.9995 - acc: 0.3930\n",
      "Epoch 368/600\n",
      " - 24s - loss: 1.9931 - acc: 0.3980\n",
      "Epoch 369/600\n",
      " - 24s - loss: 1.9865 - acc: 0.3965\n",
      "Epoch 370/600\n",
      " - 24s - loss: 1.9972 - acc: 0.3973\n",
      "Epoch 371/600\n",
      " - 24s - loss: 1.9903 - acc: 0.3952\n",
      "Epoch 372/600\n",
      " - 24s - loss: 1.9798 - acc: 0.3957\n",
      "Epoch 373/600\n",
      " - 24s - loss: 1.9881 - acc: 0.3962\n",
      "Epoch 374/600\n",
      " - 24s - loss: 1.9864 - acc: 0.3951\n",
      "Epoch 375/600\n",
      " - 24s - loss: 1.9806 - acc: 0.3962\n",
      "Epoch 376/600\n",
      " - 24s - loss: 1.9815 - acc: 0.3951\n",
      "Epoch 377/600\n",
      " - 24s - loss: 1.9918 - acc: 0.3960\n",
      "Epoch 378/600\n",
      " - 24s - loss: 1.9924 - acc: 0.3941\n",
      "Epoch 379/600\n",
      " - 24s - loss: 1.9824 - acc: 0.3976\n",
      "Epoch 380/600\n",
      " - 24s - loss: 1.9830 - acc: 0.3948\n",
      "Epoch 381/600\n",
      " - 24s - loss: 1.9860 - acc: 0.3956\n",
      "Epoch 382/600\n",
      " - 24s - loss: 1.9925 - acc: 0.3948\n",
      "Epoch 383/600\n",
      " - 24s - loss: 1.9862 - acc: 0.3959\n",
      "Epoch 384/600\n",
      " - 24s - loss: 1.9870 - acc: 0.3944\n",
      "Epoch 385/600\n",
      " - 24s - loss: 1.9896 - acc: 0.3957\n",
      "Epoch 386/600\n",
      " - 24s - loss: 1.9936 - acc: 0.3953\n",
      "Epoch 387/600\n",
      " - 24s - loss: 1.9896 - acc: 0.3979\n",
      "Epoch 388/600\n",
      " - 24s - loss: 1.9868 - acc: 0.3962\n",
      "Epoch 389/600\n",
      " - 24s - loss: 1.9858 - acc: 0.3942\n",
      "Epoch 390/600\n",
      " - 24s - loss: 1.9856 - acc: 0.3963\n",
      "Epoch 391/600\n",
      " - 24s - loss: 1.9870 - acc: 0.3969\n",
      "Epoch 392/600\n",
      " - 24s - loss: 1.9889 - acc: 0.3971\n",
      "Epoch 393/600\n",
      " - 24s - loss: 1.9907 - acc: 0.3972\n",
      "Epoch 394/600\n",
      " - 24s - loss: 1.9891 - acc: 0.3957\n",
      "Epoch 395/600\n",
      " - 24s - loss: 1.9832 - acc: 0.3956\n",
      "Epoch 396/600\n",
      " - 24s - loss: 1.9853 - acc: 0.3971\n",
      "Epoch 397/600\n",
      " - 24s - loss: 1.9966 - acc: 0.3945\n",
      "Epoch 398/600\n",
      " - 24s - loss: 1.9835 - acc: 0.3959\n",
      "Epoch 399/600\n",
      " - 24s - loss: 1.9973 - acc: 0.3942\n",
      "Epoch 400/600\n",
      " - 24s - loss: 1.9766 - acc: 0.3969\n",
      "Epoch 401/600\n",
      " - 24s - loss: 1.9889 - acc: 0.3973\n",
      "Epoch 402/600\n",
      " - 24s - loss: 1.9958 - acc: 0.3949\n",
      "Epoch 403/600\n",
      " - 24s - loss: 1.9909 - acc: 0.3955\n",
      "Epoch 404/600\n",
      " - 24s - loss: 1.9886 - acc: 0.3962\n",
      "Epoch 405/600\n",
      " - 24s - loss: 1.9870 - acc: 0.3971\n",
      "Epoch 406/600\n",
      " - 24s - loss: 1.9835 - acc: 0.3977\n",
      "Epoch 407/600\n",
      " - 24s - loss: 1.9849 - acc: 0.3962\n",
      "Epoch 408/600\n",
      " - 24s - loss: 1.9900 - acc: 0.3940\n",
      "Epoch 409/600\n",
      " - 24s - loss: 1.9819 - acc: 0.3960\n",
      "Epoch 410/600\n",
      " - 24s - loss: 1.9906 - acc: 0.3947\n",
      "Epoch 411/600\n",
      " - 24s - loss: 1.9951 - acc: 0.3990\n",
      "Epoch 412/600\n",
      " - 24s - loss: 1.9832 - acc: 0.3955\n",
      "Epoch 413/600\n",
      " - 24s - loss: 1.9846 - acc: 0.3969\n",
      "Epoch 414/600\n",
      " - 24s - loss: 1.9875 - acc: 0.3966\n",
      "Epoch 415/600\n",
      " - 24s - loss: 1.9791 - acc: 0.3973\n",
      "Epoch 416/600\n",
      " - 24s - loss: 1.9914 - acc: 0.3966\n",
      "Epoch 417/600\n",
      " - 24s - loss: 1.9779 - acc: 0.3978\n",
      "Epoch 418/600\n",
      " - 24s - loss: 1.9867 - acc: 0.3960\n",
      "Epoch 419/600\n",
      " - 24s - loss: 1.9926 - acc: 0.3945\n",
      "Epoch 420/600\n",
      " - 24s - loss: 1.9814 - acc: 0.3965\n",
      "Epoch 421/600\n",
      " - 24s - loss: 1.9877 - acc: 0.3952\n",
      "Epoch 422/600\n",
      " - 24s - loss: 1.9877 - acc: 0.3982\n",
      "Epoch 423/600\n",
      " - 24s - loss: 1.9961 - acc: 0.3941\n",
      "Epoch 424/600\n",
      " - 24s - loss: 1.9830 - acc: 0.3963\n",
      "Epoch 425/600\n",
      " - 24s - loss: 1.9946 - acc: 0.3958\n",
      "Epoch 426/600\n",
      " - 24s - loss: 1.9870 - acc: 0.3957\n",
      "Epoch 427/600\n",
      " - 24s - loss: 1.9892 - acc: 0.3958\n",
      "Epoch 428/600\n",
      " - 24s - loss: 1.9783 - acc: 0.3957\n",
      "Epoch 429/600\n",
      " - 24s - loss: 1.9865 - acc: 0.3972\n",
      "Epoch 430/600\n",
      " - 24s - loss: 1.9955 - acc: 0.3980\n",
      "Epoch 431/600\n",
      " - 24s - loss: 1.9798 - acc: 0.3968\n",
      "Epoch 432/600\n",
      " - 24s - loss: 1.9907 - acc: 0.3945\n",
      "Epoch 433/600\n",
      " - 24s - loss: 1.9780 - acc: 0.3974\n",
      "Epoch 434/600\n",
      " - 24s - loss: 1.9999 - acc: 0.3948\n",
      "Epoch 435/600\n",
      " - 24s - loss: 1.9754 - acc: 0.3992\n",
      "Epoch 436/600\n",
      " - 24s - loss: 1.9890 - acc: 0.3950\n",
      "Epoch 437/600\n",
      " - 24s - loss: 1.9899 - acc: 0.3952\n",
      "Epoch 438/600\n",
      " - 24s - loss: 1.9904 - acc: 0.3970\n",
      "Epoch 439/600\n",
      " - 24s - loss: 1.9901 - acc: 0.3957\n",
      "Epoch 440/600\n",
      " - 24s - loss: 1.9902 - acc: 0.3947\n",
      "Epoch 441/600\n",
      " - 24s - loss: 1.9736 - acc: 0.3979\n",
      "Epoch 442/600\n",
      " - 24s - loss: 1.9951 - acc: 0.3942\n",
      "Epoch 443/600\n",
      " - 24s - loss: 1.9849 - acc: 0.3972\n",
      "Epoch 444/600\n",
      " - 24s - loss: 1.9857 - acc: 0.3978\n",
      "Epoch 445/600\n",
      " - 24s - loss: 1.9871 - acc: 0.3977\n",
      "Epoch 446/600\n",
      " - 24s - loss: 1.9890 - acc: 0.3964\n",
      "Epoch 447/600\n",
      " - 24s - loss: 1.9839 - acc: 0.3978\n",
      "Epoch 448/600\n",
      " - 24s - loss: 1.9887 - acc: 0.3960\n",
      "Epoch 449/600\n",
      " - 24s - loss: 1.9737 - acc: 0.3989\n",
      "Epoch 450/600\n",
      " - 24s - loss: 1.9857 - acc: 0.3956\n",
      "Epoch 451/600\n",
      " - 24s - loss: 1.9926 - acc: 0.3949\n",
      "Epoch 452/600\n",
      " - 24s - loss: 1.9861 - acc: 0.3957\n",
      "Epoch 453/600\n",
      " - 24s - loss: 1.9806 - acc: 0.3976\n",
      "Epoch 454/600\n",
      " - 24s - loss: 1.9876 - acc: 0.3946\n",
      "Epoch 455/600\n",
      " - 24s - loss: 1.9851 - acc: 0.3982\n",
      "Epoch 456/600\n",
      " - 24s - loss: 1.9818 - acc: 0.3946\n",
      "Epoch 457/600\n",
      " - 24s - loss: 1.9919 - acc: 0.3937\n",
      "Epoch 458/600\n",
      " - 24s - loss: 2.0078 - acc: 0.3949\n",
      "Epoch 459/600\n",
      " - 24s - loss: 1.9900 - acc: 0.3957\n",
      "Epoch 460/600\n",
      " - 24s - loss: 1.9819 - acc: 0.3970\n",
      "Epoch 461/600\n",
      " - 24s - loss: 1.9847 - acc: 0.3971\n",
      "Epoch 462/600\n",
      " - 24s - loss: 1.9931 - acc: 0.3978\n",
      "Epoch 463/600\n",
      " - 24s - loss: 1.9783 - acc: 0.3960\n",
      "Epoch 464/600\n",
      " - 24s - loss: 1.9985 - acc: 0.3936\n",
      "Epoch 465/600\n",
      " - 24s - loss: 1.9768 - acc: 0.3973\n",
      "Epoch 466/600\n",
      " - 24s - loss: 1.9878 - acc: 0.3948\n",
      "Epoch 467/600\n",
      " - 24s - loss: 2.0073 - acc: 0.3959\n",
      "Epoch 468/600\n",
      " - 24s - loss: 1.9766 - acc: 0.3972\n",
      "Epoch 469/600\n",
      " - 24s - loss: 1.9854 - acc: 0.3985\n",
      "Epoch 470/600\n",
      " - 24s - loss: 1.9775 - acc: 0.3980\n",
      "Epoch 471/600\n",
      " - 24s - loss: 1.9894 - acc: 0.3961\n",
      "Epoch 472/600\n",
      " - 24s - loss: 1.9955 - acc: 0.3949\n",
      "Epoch 473/600\n",
      " - 24s - loss: 1.9966 - acc: 0.3951\n",
      "Epoch 474/600\n",
      " - 24s - loss: 1.9855 - acc: 0.3971\n",
      "Epoch 475/600\n",
      " - 24s - loss: 1.9937 - acc: 0.3965\n",
      "Epoch 476/600\n",
      " - 24s - loss: 1.9914 - acc: 0.3976\n",
      "Epoch 477/600\n",
      " - 24s - loss: 1.9786 - acc: 0.3966\n",
      "Epoch 478/600\n",
      " - 24s - loss: 1.9935 - acc: 0.3974\n",
      "Epoch 479/600\n",
      " - 24s - loss: 1.9861 - acc: 0.3973\n",
      "Epoch 480/600\n",
      " - 24s - loss: 1.9878 - acc: 0.3973\n",
      "Epoch 481/600\n",
      " - 24s - loss: 1.9949 - acc: 0.3953\n",
      "Epoch 482/600\n",
      " - 24s - loss: 1.9831 - acc: 0.3961\n",
      "Epoch 483/600\n",
      " - 24s - loss: 1.9871 - acc: 0.3968\n",
      "Epoch 484/600\n",
      " - 24s - loss: 1.9962 - acc: 0.3954\n",
      "Epoch 485/600\n",
      " - 24s - loss: 1.9997 - acc: 0.3955\n",
      "Epoch 486/600\n",
      " - 24s - loss: 1.9823 - acc: 0.3976\n",
      "Epoch 487/600\n",
      " - 24s - loss: 1.9955 - acc: 0.3940\n",
      "Epoch 488/600\n",
      " - 24s - loss: 1.9787 - acc: 0.3955\n",
      "Epoch 489/600\n",
      " - 24s - loss: 2.0009 - acc: 0.3939\n",
      "Epoch 490/600\n",
      " - 25s - loss: 1.9965 - acc: 0.3958\n",
      "Epoch 491/600\n",
      " - 24s - loss: 1.9982 - acc: 0.3944\n",
      "Epoch 492/600\n",
      " - 24s - loss: 1.9957 - acc: 0.3961\n",
      "Epoch 493/600\n",
      " - 24s - loss: 1.9953 - acc: 0.3971\n",
      "Epoch 494/600\n",
      " - 24s - loss: 1.9866 - acc: 0.3967\n",
      "Epoch 495/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 24s - loss: 1.9993 - acc: 0.3966\n",
      "Epoch 496/600\n",
      " - 24s - loss: 2.0092 - acc: 0.3920\n",
      "Epoch 497/600\n",
      " - 24s - loss: 1.9861 - acc: 0.3979\n",
      "Epoch 498/600\n",
      " - 24s - loss: 2.0029 - acc: 0.3945\n",
      "Epoch 499/600\n",
      " - 24s - loss: 2.0042 - acc: 0.3940\n",
      "Epoch 500/600\n",
      " - 24s - loss: 1.9805 - acc: 0.3955\n",
      "Epoch 501/600\n",
      " - 24s - loss: 1.9860 - acc: 0.3965\n",
      "Epoch 502/600\n",
      " - 24s - loss: 1.9983 - acc: 0.3931\n",
      "Epoch 503/600\n",
      " - 24s - loss: 1.9928 - acc: 0.3961\n",
      "Epoch 504/600\n",
      " - 24s - loss: 1.9898 - acc: 0.3937\n",
      "Epoch 505/600\n",
      " - 24s - loss: 1.9936 - acc: 0.3958\n",
      "Epoch 506/600\n",
      " - 24s - loss: 2.0005 - acc: 0.3950\n",
      "Epoch 507/600\n",
      " - 24s - loss: 1.9937 - acc: 0.3948\n",
      "Epoch 508/600\n",
      " - 24s - loss: 1.9918 - acc: 0.3976\n",
      "Epoch 509/600\n",
      " - 24s - loss: 1.9949 - acc: 0.3949\n",
      "Epoch 510/600\n",
      " - 24s - loss: 1.9799 - acc: 0.3981\n",
      "Epoch 511/600\n",
      " - 24s - loss: 1.9858 - acc: 0.3960\n",
      "Epoch 512/600\n",
      " - 24s - loss: 1.9968 - acc: 0.3945\n",
      "Epoch 513/600\n",
      " - 24s - loss: 1.9942 - acc: 0.3962\n",
      "Epoch 514/600\n",
      " - 24s - loss: 1.9949 - acc: 0.3953\n",
      "Epoch 515/600\n",
      " - 24s - loss: 2.0003 - acc: 0.3943\n",
      "Epoch 516/600\n",
      " - 24s - loss: 2.0091 - acc: 0.3938\n",
      "Epoch 517/600\n",
      " - 24s - loss: 1.9848 - acc: 0.3957\n",
      "Epoch 518/600\n",
      " - 24s - loss: 2.0207 - acc: 0.3935\n",
      "Epoch 519/600\n",
      " - 24s - loss: 2.0089 - acc: 0.3939\n",
      "Epoch 520/600\n",
      " - 24s - loss: 2.0120 - acc: 0.3936\n",
      "Epoch 521/600\n",
      " - 24s - loss: 1.9958 - acc: 0.3957\n",
      "Epoch 522/600\n",
      " - 24s - loss: 2.0061 - acc: 0.3942\n",
      "Epoch 523/600\n",
      " - 24s - loss: 2.0063 - acc: 0.3935\n",
      "Epoch 524/600\n",
      " - 24s - loss: 2.0020 - acc: 0.3932\n",
      "Epoch 525/600\n",
      " - 24s - loss: 1.9956 - acc: 0.3966\n",
      "Epoch 526/600\n",
      " - 24s - loss: 1.9845 - acc: 0.4001\n",
      "Epoch 527/600\n",
      " - 25s - loss: 1.9999 - acc: 0.3970\n",
      "Epoch 528/600\n",
      " - 24s - loss: 1.9948 - acc: 0.3952\n",
      "Epoch 529/600\n",
      " - 24s - loss: 2.0004 - acc: 0.3971\n",
      "Epoch 530/600\n",
      " - 24s - loss: 1.9998 - acc: 0.3961\n",
      "Epoch 531/600\n",
      " - 24s - loss: 1.9909 - acc: 0.3952\n",
      "Epoch 532/600\n",
      " - 24s - loss: 2.0224 - acc: 0.3908\n",
      "Epoch 533/600\n",
      " - 24s - loss: 2.0108 - acc: 0.3954\n",
      "Epoch 534/600\n",
      " - 24s - loss: 1.9906 - acc: 0.3982\n",
      "Epoch 535/600\n",
      " - 24s - loss: 1.9951 - acc: 0.3962\n",
      "Epoch 536/600\n",
      " - 24s - loss: 1.9879 - acc: 0.3967\n",
      "Epoch 537/600\n",
      " - 24s - loss: 1.9861 - acc: 0.3987\n",
      "Epoch 538/600\n",
      " - 24s - loss: 2.0005 - acc: 0.3948\n",
      "Epoch 539/600\n",
      " - 24s - loss: 1.9908 - acc: 0.3954\n",
      "Epoch 540/600\n",
      " - 24s - loss: 1.9987 - acc: 0.3925\n",
      "Epoch 541/600\n",
      " - 24s - loss: 2.0030 - acc: 0.3946\n",
      "Epoch 542/600\n",
      " - 24s - loss: 2.0023 - acc: 0.3950\n",
      "Epoch 543/600\n",
      " - 24s - loss: 2.0014 - acc: 0.3945\n",
      "Epoch 544/600\n",
      " - 24s - loss: 1.9914 - acc: 0.3966\n",
      "Epoch 545/600\n",
      " - 24s - loss: 2.0218 - acc: 0.3922\n",
      "Epoch 546/600\n",
      " - 24s - loss: 1.9979 - acc: 0.3958\n",
      "Epoch 547/600\n",
      " - 24s - loss: 2.0055 - acc: 0.3960\n",
      "Epoch 548/600\n",
      " - 24s - loss: 2.0089 - acc: 0.3936\n",
      "Epoch 549/600\n",
      " - 24s - loss: 1.9889 - acc: 0.3969\n",
      "Epoch 550/600\n",
      " - 24s - loss: 2.0079 - acc: 0.3927\n",
      "Epoch 551/600\n",
      " - 24s - loss: 2.0001 - acc: 0.3925\n",
      "Epoch 552/600\n",
      " - 24s - loss: 2.0005 - acc: 0.3949\n",
      "Epoch 553/600\n",
      " - 24s - loss: 1.9983 - acc: 0.3960\n",
      "Epoch 554/600\n",
      " - 24s - loss: 1.9959 - acc: 0.3971\n",
      "Epoch 555/600\n",
      " - 24s - loss: 2.0043 - acc: 0.3969\n",
      "Epoch 556/600\n",
      " - 24s - loss: 2.0123 - acc: 0.3935\n",
      "Epoch 557/600\n",
      " - 24s - loss: 2.0168 - acc: 0.3936\n",
      "Epoch 558/600\n",
      " - 24s - loss: 2.0028 - acc: 0.3944\n",
      "Epoch 559/600\n",
      " - 24s - loss: 2.0056 - acc: 0.3930\n",
      "Epoch 560/600\n",
      " - 24s - loss: 1.9853 - acc: 0.3959\n",
      "Epoch 561/600\n",
      " - 24s - loss: 2.0114 - acc: 0.3936\n",
      "Epoch 562/600\n",
      " - 24s - loss: 2.0095 - acc: 0.3949\n",
      "Epoch 563/600\n",
      " - 24s - loss: 2.0025 - acc: 0.3950\n",
      "Epoch 564/600\n",
      " - 24s - loss: 2.0021 - acc: 0.3935\n",
      "Epoch 565/600\n",
      " - 24s - loss: 1.9976 - acc: 0.3937\n",
      "Epoch 566/600\n",
      " - 24s - loss: 2.0113 - acc: 0.3941\n",
      "Epoch 567/600\n",
      " - 24s - loss: 2.0005 - acc: 0.3922\n",
      "Epoch 568/600\n",
      " - 24s - loss: 2.0082 - acc: 0.3945\n",
      "Epoch 569/600\n",
      " - 24s - loss: 2.0010 - acc: 0.3948\n",
      "Epoch 570/600\n",
      " - 24s - loss: 2.0058 - acc: 0.3962\n",
      "Epoch 571/600\n",
      " - 24s - loss: 1.9906 - acc: 0.3982\n",
      "Epoch 572/600\n",
      " - 24s - loss: 2.0155 - acc: 0.3914\n",
      "Epoch 573/600\n",
      " - 24s - loss: 1.9965 - acc: 0.3951\n",
      "Epoch 574/600\n",
      " - 24s - loss: 1.9952 - acc: 0.3968\n",
      "Epoch 575/600\n",
      " - 24s - loss: 2.0240 - acc: 0.3939\n",
      "Epoch 576/600\n",
      " - 24s - loss: 2.0029 - acc: 0.3953\n",
      "Epoch 577/600\n",
      " - 24s - loss: 1.9964 - acc: 0.3959\n",
      "Epoch 578/600\n",
      " - 24s - loss: 2.0113 - acc: 0.3924\n",
      "Epoch 579/600\n",
      " - 24s - loss: 2.0111 - acc: 0.3941\n",
      "Epoch 580/600\n",
      " - 24s - loss: 2.0069 - acc: 0.3949\n",
      "Epoch 581/600\n",
      " - 24s - loss: 1.9953 - acc: 0.3952\n",
      "Epoch 582/600\n",
      " - 24s - loss: 2.0238 - acc: 0.3936\n",
      "Epoch 583/600\n",
      " - 24s - loss: 2.0020 - acc: 0.3948\n",
      "Epoch 584/600\n",
      " - 24s - loss: 2.0146 - acc: 0.3934\n",
      "Epoch 585/600\n",
      " - 24s - loss: 2.0101 - acc: 0.3943\n",
      "Epoch 586/600\n",
      " - 24s - loss: 2.0201 - acc: 0.3906\n",
      "Epoch 587/600\n",
      " - 24s - loss: 1.9943 - acc: 0.3981\n",
      "Epoch 588/600\n",
      " - 24s - loss: 2.0227 - acc: 0.3916\n",
      "Epoch 589/600\n",
      " - 24s - loss: 2.0123 - acc: 0.3928\n",
      "Epoch 590/600\n",
      " - 24s - loss: 2.0018 - acc: 0.3943\n",
      "Epoch 591/600\n",
      " - 24s - loss: 2.0149 - acc: 0.3912\n",
      "Epoch 592/600\n",
      " - 24s - loss: 2.0057 - acc: 0.3930\n",
      "Epoch 593/600\n",
      " - 24s - loss: 2.0270 - acc: 0.3903\n",
      "Epoch 594/600\n",
      " - 24s - loss: 2.0077 - acc: 0.3947\n",
      "Epoch 595/600\n",
      " - 24s - loss: 2.0069 - acc: 0.3944\n",
      "Epoch 596/600\n",
      " - 24s - loss: 2.0116 - acc: 0.3941\n",
      "Epoch 597/600\n",
      " - 24s - loss: 2.0119 - acc: 0.3935\n",
      "Epoch 598/600\n",
      " - 24s - loss: 2.0221 - acc: 0.3929\n",
      "Epoch 599/600\n",
      " - 24s - loss: 2.0174 - acc: 0.3921\n",
      "Epoch 600/600\n",
      " - 22s - loss: 2.0236 - acc: 0.3925\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2b28b528198>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#compile and fit the model\n",
    "\n",
    "model.compile(optimizer='adam', \n",
    "              loss='categorical_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "model.fit(\n",
    "    X_train_scaled,\n",
    "    y_train_categorical,\n",
    "    epochs=600,\n",
    "    shuffle=True,\n",
    "    verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normal Neural Network - Loss: 3.9309288039827712, Accuracy: 0.2985486840680169\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 300)               1200      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 300)               90300     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 300)               90300     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 300)               90300     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 176)               52976     \n",
      "=================================================================\n",
      "Total params: 325,076\n",
      "Trainable params: 325,076\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Quantify the trained model\n",
    "model_loss, model_accuracy = model.evaluate(X_test_scaled, y_test_categorical, verbose=2)\n",
    "print(f\"Normal Neural Network - Loss: {model_loss}, Accuracy: {model_accuracy}\")\n",
    "\n",
    "model.summary()\n",
    "\n",
    "#save the model\n",
    "model.save(\"beer_3p_all_styles.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.19861203, -0.45382044, -0.12585185],\n",
       "       [ 0.64577732,  1.15854218,  0.83074592],\n",
       "       [ 0.70965808, -0.31960958,  1.30527867],\n",
       "       [-0.52004648, -0.39656325,  0.4348835 ],\n",
       "       [-0.67442497,  0.34457389, -0.86317699],\n",
       "       [ 1.21538073,  0.35946076, -0.21791288],\n",
       "       [ 0.49672223, -0.2999131 , -0.59368925],\n",
       "       [-0.80750988, -0.14165421,  1.18308858],\n",
       "       [-0.03561741, -0.41419846, -0.54431107],\n",
       "       [-0.08352798, -0.25090094, -0.76525753]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_scaled[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted classes: [102  13  19  34  10 172 134  58 134 134]\n",
      "Actual Labels: [4, 67, 134, 92, 7, 147, 10, 6, 7, 169]\n"
     ]
    }
   ],
   "source": [
    "###TEST THE MODEL - THIS DOESN'T GO IN FINAL CODE\n",
    "encoded_predictions = model.predict_classes(X_test_scaled[:10])\n",
    "\n",
    "#decode the \n",
    "prediction_labels = label_encoder.inverse_transform(encoded_predictions)\n",
    "\n",
    "#print predicted vs actual\n",
    "print(f\"Predicted classes: {prediction_labels}\")\n",
    "print(f\"Actual Labels: {list(y_test[:10])}\")\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###Call the saved model and run a prediction\n",
    "\n",
    "# Load the model\n",
    "from keras.models import load_model\n",
    "model = load_model(\"beer_7p_all_styles.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#tell it what to run based on user input - AJAX here?\n",
    "\n",
    "input_beer = #call user input\n",
    "\n",
    "input_beer_scaled = #how to scale our input?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#run a prediction\n",
    "# Make predictions\n",
    "\n",
    "styleID_guess = model.predict_classes(input_beer_scaled) #Instead, do we want to show the % chance of each?\n",
    "\n",
    "styleID = #translate the style ID to a style name"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
