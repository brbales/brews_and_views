{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Dependencies to Visualize the model\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Filepaths, numpy, and Tensorflow\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Sklearn scaling\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Keras\n",
    "from keras.models import Sequential\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading and Preprocessing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['BeerID', 'Name', 'Style', 'StyleID', 'OG', 'FG', 'ABV', 'IBU', 'Color',\n",
      "       'BoilSize', 'BoilTime', 'Efficiency', 'ViewCount', 'BrewCount',\n",
      "       'LastUpdated', 'Category', 'clusters_7param', 'clusters_3param'],\n",
      "      dtype='object')\n",
      "(73861, 7) (73861,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    45\n",
       "1    45\n",
       "2    45\n",
       "3    45\n",
       "4    45\n",
       "Name: StyleID, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import data from Ethan\n",
    "all_beer_df = pd.read_csv(\"data_add_3param_cluster.csv\", encoding=\"latin1\" )\n",
    "\n",
    "#trim data to needed X colums\n",
    "print(all_beer_df.columns)\n",
    "beer_char = all_beer_df[[\"OG\",\"FG\",\"ABV\",\"IBU\",\"Color\",\"BoilTime\",\"Efficiency\"]]\n",
    "\n",
    "#Set beer_char as X \n",
    "X=beer_char\n",
    "X.head()\n",
    "\n",
    "#set y data\n",
    "y=all_beer_df[\"StyleID\"]\n",
    "print(X.shape, y.shape)\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "176\n"
     ]
    }
   ],
   "source": [
    "#find the number of unique beer styles and set as variable\n",
    "\n",
    "#create an array of unique values from the output dataset\n",
    "style_array = pd.unique(y.values)\n",
    "\n",
    "#set the count as the length of the output array\n",
    "style_count = len(style_array)\n",
    "\n",
    "print(style_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###Scale and pre-process the data\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1, stratify=y)\n",
    "X_scaler = StandardScaler().fit(X_train)\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)\n",
    "\n",
    "\n",
    "# Step 1: Label-encode data set\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(y_train)\n",
    "encoded_y_train = label_encoder.transform(y_train)\n",
    "encoded_y_test = label_encoder.transform(y_test)\n",
    "\n",
    "# Step 2: Convert encoded labels to one-hot-encoding\n",
    "y_train_categorical = to_categorical(encoded_y_train)\n",
    "y_test_categorical = to_categorical(encoded_y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n"
     ]
    }
   ],
   "source": [
    "#check the categorical results\n",
    "print(y_train_categorical[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Deep Learning Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#setup a sequential model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "model = Sequential()\n",
    "# Add the first layer where the input dimensions are the 5 inputs (don't have to specify batch size)\n",
    "# We can also choose our activation function. `relu` is a common\n",
    "model.add(Dense(units=300, activation='relu', input_dim=X_train.shape[1]))\n",
    "\n",
    "#add a second hidden layer\n",
    "model.add(Dense(units=300, activation='relu'))\n",
    "\n",
    "#add a second hidden layer\n",
    "model.add(Dense(units=300, activation='relu'))\n",
    "\n",
    "#add a third hidden layer\n",
    "model.add(Dense(units=300, activation='relu'))\n",
    "\n",
    "#specify the output\n",
    "model.add(Dense(units=style_count, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/600\n",
      " - 20s - loss: 2.9629 - acc: 0.2940\n",
      "Epoch 2/600\n",
      " - 25s - loss: 2.7319 - acc: 0.3218\n",
      "Epoch 3/600\n",
      " - 25s - loss: 2.6909 - acc: 0.3265\n",
      "Epoch 4/600\n",
      " - 27s - loss: 2.6637 - acc: 0.3297\n",
      "Epoch 5/600\n",
      " - 26s - loss: 2.6406 - acc: 0.3350\n",
      "Epoch 6/600\n",
      " - 26s - loss: 2.6201 - acc: 0.3371\n",
      "Epoch 7/600\n",
      " - 26s - loss: 2.6027 - acc: 0.3384\n",
      "Epoch 8/600\n",
      " - 26s - loss: 2.5884 - acc: 0.3395\n",
      "Epoch 9/600\n",
      " - 28s - loss: 2.5715 - acc: 0.3403\n",
      "Epoch 10/600\n",
      " - 28s - loss: 2.5558 - acc: 0.3433\n",
      "Epoch 11/600\n",
      " - 29s - loss: 2.5435 - acc: 0.3432\n",
      "Epoch 12/600\n",
      " - 28s - loss: 2.5291 - acc: 0.3441\n",
      "Epoch 13/600\n",
      " - 28s - loss: 2.5133 - acc: 0.3472\n",
      "Epoch 14/600\n",
      " - 27s - loss: 2.5036 - acc: 0.3468\n",
      "Epoch 15/600\n",
      " - 26s - loss: 2.4895 - acc: 0.3495\n",
      "Epoch 16/600\n",
      " - 25s - loss: 2.4763 - acc: 0.3505\n",
      "Epoch 17/600\n",
      " - 25s - loss: 2.4653 - acc: 0.3514\n",
      "Epoch 18/600\n",
      " - 25s - loss: 2.4503 - acc: 0.3544\n",
      "Epoch 19/600\n",
      " - 25s - loss: 2.4382 - acc: 0.3548\n",
      "Epoch 20/600\n",
      " - 25s - loss: 2.4266 - acc: 0.3561\n",
      "Epoch 21/600\n",
      " - 25s - loss: 2.4125 - acc: 0.3567\n",
      "Epoch 22/600\n",
      " - 25s - loss: 2.3984 - acc: 0.3583\n",
      "Epoch 23/600\n",
      " - 26s - loss: 2.3858 - acc: 0.3608\n",
      "Epoch 24/600\n",
      " - 26s - loss: 2.3722 - acc: 0.3614\n",
      "Epoch 25/600\n",
      " - 26s - loss: 2.3579 - acc: 0.3636\n",
      "Epoch 26/600\n",
      " - 26s - loss: 2.3482 - acc: 0.3673\n",
      "Epoch 27/600\n",
      " - 26s - loss: 2.3308 - acc: 0.3685\n",
      "Epoch 28/600\n",
      " - 25s - loss: 2.3214 - acc: 0.3670\n",
      "Epoch 29/600\n",
      " - 26s - loss: 2.3085 - acc: 0.3702\n",
      "Epoch 30/600\n",
      " - 26s - loss: 2.2959 - acc: 0.3702\n",
      "Epoch 31/600\n",
      " - 25s - loss: 2.2824 - acc: 0.3732\n",
      "Epoch 32/600\n",
      " - 26s - loss: 2.2694 - acc: 0.3762\n",
      "Epoch 33/600\n",
      " - 26s - loss: 2.2601 - acc: 0.3762\n",
      "Epoch 34/600\n",
      " - 26s - loss: 2.2471 - acc: 0.3789\n",
      "Epoch 35/600\n",
      " - 26s - loss: 2.2365 - acc: 0.3795\n",
      "Epoch 36/600\n",
      " - 26s - loss: 2.2203 - acc: 0.3828\n",
      "Epoch 37/600\n",
      " - 25s - loss: 2.2119 - acc: 0.3840\n",
      "Epoch 38/600\n",
      " - 26s - loss: 2.2015 - acc: 0.3834\n",
      "Epoch 39/600\n",
      " - 26s - loss: 2.1894 - acc: 0.3862\n",
      "Epoch 40/600\n",
      " - 26s - loss: 2.1790 - acc: 0.3876\n",
      "Epoch 41/600\n",
      " - 26s - loss: 2.1669 - acc: 0.3913\n",
      "Epoch 42/600\n",
      " - 25s - loss: 2.1537 - acc: 0.3922\n",
      "Epoch 43/600\n",
      " - 26s - loss: 2.1442 - acc: 0.3918\n",
      "Epoch 44/600\n",
      " - 25s - loss: 2.1369 - acc: 0.3950\n",
      "Epoch 45/600\n",
      " - 26s - loss: 2.1259 - acc: 0.3972\n",
      "Epoch 46/600\n",
      " - 26s - loss: 2.1158 - acc: 0.3964\n",
      "Epoch 47/600\n",
      " - 26s - loss: 2.1063 - acc: 0.3981\n",
      "Epoch 48/600\n",
      " - 26s - loss: 2.0973 - acc: 0.4006\n",
      "Epoch 49/600\n",
      " - 25s - loss: 2.0902 - acc: 0.4026\n",
      "Epoch 50/600\n",
      " - 26s - loss: 2.0738 - acc: 0.4045\n",
      "Epoch 51/600\n",
      " - 25s - loss: 2.0720 - acc: 0.4049\n",
      "Epoch 52/600\n",
      " - 26s - loss: 2.0548 - acc: 0.4087\n",
      "Epoch 53/600\n",
      " - 25s - loss: 2.0463 - acc: 0.4101\n",
      "Epoch 54/600\n",
      " - 25s - loss: 2.0422 - acc: 0.4095\n",
      "Epoch 55/600\n",
      " - 26s - loss: 2.0297 - acc: 0.4122\n",
      "Epoch 56/600\n",
      " - 25s - loss: 2.0218 - acc: 0.4130\n",
      "Epoch 57/600\n",
      " - 26s - loss: 2.0113 - acc: 0.4155\n",
      "Epoch 58/600\n",
      " - 25s - loss: 2.0075 - acc: 0.4158\n",
      "Epoch 59/600\n",
      " - 26s - loss: 1.9975 - acc: 0.4163\n",
      "Epoch 60/600\n",
      " - 26s - loss: 1.9972 - acc: 0.4157\n",
      "Epoch 61/600\n",
      " - 26s - loss: 1.9869 - acc: 0.4191\n",
      "Epoch 62/600\n",
      " - 25s - loss: 1.9723 - acc: 0.4223\n",
      "Epoch 63/600\n",
      " - 26s - loss: 1.9643 - acc: 0.4253\n",
      "Epoch 64/600\n",
      " - 25s - loss: 1.9607 - acc: 0.4236\n",
      "Epoch 65/600\n",
      " - 26s - loss: 1.9474 - acc: 0.4262\n",
      "Epoch 66/600\n",
      " - 25s - loss: 1.9396 - acc: 0.4276\n",
      "Epoch 67/600\n",
      " - 26s - loss: 1.9360 - acc: 0.4294\n",
      "Epoch 68/600\n",
      " - 26s - loss: 1.9329 - acc: 0.4281\n",
      "Epoch 69/600\n",
      " - 26s - loss: 1.9204 - acc: 0.4325\n",
      "Epoch 70/600\n",
      " - 25s - loss: 1.9164 - acc: 0.4309\n",
      "Epoch 71/600\n",
      " - 26s - loss: 1.9058 - acc: 0.4336\n",
      "Epoch 72/600\n",
      " - 26s - loss: 1.9066 - acc: 0.4330\n",
      "Epoch 73/600\n",
      " - 26s - loss: 1.8888 - acc: 0.4377\n",
      "Epoch 74/600\n",
      " - 25s - loss: 1.8894 - acc: 0.4397\n",
      "Epoch 75/600\n",
      " - 26s - loss: 1.8809 - acc: 0.4383\n",
      "Epoch 76/600\n",
      " - 25s - loss: 1.8784 - acc: 0.4390\n",
      "Epoch 77/600\n",
      " - 25s - loss: 1.8619 - acc: 0.4449\n",
      "Epoch 78/600\n",
      " - 25s - loss: 1.8585 - acc: 0.4430\n",
      "Epoch 79/600\n",
      " - 25s - loss: 1.8508 - acc: 0.4456\n",
      "Epoch 80/600\n",
      " - 26s - loss: 1.8537 - acc: 0.4440\n",
      "Epoch 81/600\n",
      " - 25s - loss: 1.8475 - acc: 0.4459\n",
      "Epoch 82/600\n",
      " - 26s - loss: 1.8407 - acc: 0.4458\n",
      "Epoch 83/600\n",
      " - 26s - loss: 1.8324 - acc: 0.4499\n",
      "Epoch 84/600\n",
      " - 26s - loss: 1.8279 - acc: 0.4501\n",
      "Epoch 85/600\n",
      " - 26s - loss: 1.8232 - acc: 0.4514\n",
      "Epoch 86/600\n",
      " - 25s - loss: 1.8065 - acc: 0.4559\n",
      "Epoch 87/600\n",
      " - 26s - loss: 1.8070 - acc: 0.4542\n",
      "Epoch 88/600\n",
      " - 26s - loss: 1.8025 - acc: 0.4540\n",
      "Epoch 89/600\n",
      " - 25s - loss: 1.8053 - acc: 0.4540\n",
      "Epoch 90/600\n",
      " - 25s - loss: 1.7869 - acc: 0.4603\n",
      "Epoch 91/600\n",
      " - 25s - loss: 1.7928 - acc: 0.4567\n",
      "Epoch 92/600\n",
      " - 26s - loss: 1.7773 - acc: 0.4609\n",
      "Epoch 93/600\n",
      " - 26s - loss: 1.7807 - acc: 0.4605\n",
      "Epoch 94/600\n",
      " - 26s - loss: 1.7782 - acc: 0.4607\n",
      "Epoch 95/600\n",
      " - 26s - loss: 1.7670 - acc: 0.4663\n",
      "Epoch 96/600\n",
      " - 26s - loss: 1.7601 - acc: 0.4637\n",
      "Epoch 97/600\n",
      " - 25s - loss: 1.7622 - acc: 0.4634\n",
      "Epoch 98/600\n",
      " - 26s - loss: 1.7581 - acc: 0.4653\n",
      "Epoch 99/600\n",
      " - 25s - loss: 1.7506 - acc: 0.4670\n",
      "Epoch 100/600\n",
      " - 26s - loss: 1.7354 - acc: 0.4692\n",
      "Epoch 101/600\n",
      " - 25s - loss: 1.7375 - acc: 0.4702\n",
      "Epoch 102/600\n",
      " - 26s - loss: 1.7351 - acc: 0.4707\n",
      "Epoch 103/600\n",
      " - 26s - loss: 1.7271 - acc: 0.4731\n",
      "Epoch 104/600\n",
      " - 25s - loss: 1.7245 - acc: 0.4703\n",
      "Epoch 105/600\n",
      " - 25s - loss: 1.7219 - acc: 0.4744\n",
      "Epoch 106/600\n",
      " - 26s - loss: 1.7171 - acc: 0.4766\n",
      "Epoch 107/600\n",
      " - 26s - loss: 1.7087 - acc: 0.4776\n",
      "Epoch 108/600\n",
      " - 25s - loss: 1.7119 - acc: 0.4770\n",
      "Epoch 109/600\n",
      " - 25s - loss: 1.7027 - acc: 0.4786\n",
      "Epoch 110/600\n",
      " - 25s - loss: 1.6992 - acc: 0.4813\n",
      "Epoch 111/600\n",
      " - 25s - loss: 1.6995 - acc: 0.4785\n",
      "Epoch 112/600\n",
      " - 26s - loss: 1.6931 - acc: 0.4802\n",
      "Epoch 113/600\n",
      " - 25s - loss: 1.6923 - acc: 0.4804\n",
      "Epoch 114/600\n",
      " - 26s - loss: 1.6783 - acc: 0.4819\n",
      "Epoch 115/600\n",
      " - 25s - loss: 1.6768 - acc: 0.4842\n",
      "Epoch 116/600\n",
      " - 26s - loss: 1.6719 - acc: 0.4851\n",
      "Epoch 117/600\n",
      " - 25s - loss: 1.6763 - acc: 0.4844\n",
      "Epoch 118/600\n",
      " - 26s - loss: 1.6643 - acc: 0.4868\n",
      "Epoch 119/600\n",
      " - 26s - loss: 1.6615 - acc: 0.4893\n",
      "Epoch 120/600\n",
      " - 26s - loss: 1.6637 - acc: 0.4887\n",
      "Epoch 121/600\n",
      " - 25s - loss: 1.6573 - acc: 0.4893\n",
      "Epoch 122/600\n",
      " - 24s - loss: 1.6553 - acc: 0.4900\n",
      "Epoch 123/600\n",
      " - 24s - loss: 1.6547 - acc: 0.4892\n",
      "Epoch 124/600\n",
      " - 24s - loss: 1.6513 - acc: 0.4909\n",
      "Epoch 125/600\n",
      " - 24s - loss: 1.6305 - acc: 0.4943\n",
      "Epoch 126/600\n",
      " - 24s - loss: 1.6443 - acc: 0.4920\n",
      "Epoch 127/600\n",
      " - 24s - loss: 1.6291 - acc: 0.4955\n",
      "Epoch 128/600\n",
      " - 24s - loss: 1.6317 - acc: 0.4964\n",
      "Epoch 129/600\n",
      " - 24s - loss: 1.6281 - acc: 0.4941\n",
      "Epoch 130/600\n",
      " - 24s - loss: 1.6384 - acc: 0.4949\n",
      "Epoch 131/600\n",
      " - 24s - loss: 1.6226 - acc: 0.4977\n",
      "Epoch 132/600\n",
      " - 24s - loss: 1.6219 - acc: 0.4970\n",
      "Epoch 133/600\n",
      " - 24s - loss: 1.6081 - acc: 0.5001\n",
      "Epoch 134/600\n",
      " - 24s - loss: 1.6278 - acc: 0.4962\n",
      "Epoch 135/600\n",
      " - 24s - loss: 1.6153 - acc: 0.4988\n",
      "Epoch 136/600\n",
      " - 24s - loss: 1.6108 - acc: 0.5007\n",
      "Epoch 137/600\n",
      " - 24s - loss: 1.6024 - acc: 0.5019\n",
      "Epoch 138/600\n",
      " - 24s - loss: 1.5917 - acc: 0.5053\n",
      "Epoch 139/600\n",
      " - 24s - loss: 1.6169 - acc: 0.5007\n",
      "Epoch 140/600\n",
      " - 24s - loss: 1.6022 - acc: 0.5032\n",
      "Epoch 141/600\n",
      " - 24s - loss: 1.5879 - acc: 0.5063\n",
      "Epoch 142/600\n",
      " - 24s - loss: 1.5957 - acc: 0.5037\n",
      "Epoch 143/600\n",
      " - 24s - loss: 1.6064 - acc: 0.5045\n",
      "Epoch 144/600\n",
      " - 24s - loss: 1.5733 - acc: 0.5100\n",
      "Epoch 145/600\n",
      " - 24s - loss: 1.5865 - acc: 0.5064\n",
      "Epoch 146/600\n",
      " - 24s - loss: 1.5674 - acc: 0.5111\n",
      "Epoch 147/600\n",
      " - 24s - loss: 1.5770 - acc: 0.5073\n",
      "Epoch 148/600\n",
      " - 24s - loss: 1.5991 - acc: 0.5041\n",
      "Epoch 149/600\n",
      " - 24s - loss: 1.5560 - acc: 0.5160\n",
      "Epoch 150/600\n",
      " - 24s - loss: 1.5548 - acc: 0.5145\n",
      "Epoch 151/600\n",
      " - 24s - loss: 1.5727 - acc: 0.5113\n",
      "Epoch 152/600\n",
      " - 24s - loss: 1.5595 - acc: 0.5146\n",
      "Epoch 153/600\n",
      " - 24s - loss: 1.5690 - acc: 0.5096\n",
      "Epoch 154/600\n",
      " - 24s - loss: 1.5658 - acc: 0.5116\n",
      "Epoch 155/600\n",
      " - 24s - loss: 1.5438 - acc: 0.5166\n",
      "Epoch 156/600\n",
      " - 24s - loss: 1.5548 - acc: 0.5166\n",
      "Epoch 157/600\n",
      " - 24s - loss: 1.5346 - acc: 0.5220\n",
      "Epoch 158/600\n",
      " - 24s - loss: 1.5472 - acc: 0.5152\n",
      "Epoch 159/600\n",
      " - 24s - loss: 1.5435 - acc: 0.5159\n",
      "Epoch 160/600\n",
      " - 24s - loss: 1.5576 - acc: 0.5152\n",
      "Epoch 161/600\n",
      " - 24s - loss: 1.5242 - acc: 0.5231\n",
      "Epoch 162/600\n",
      " - 24s - loss: 1.5345 - acc: 0.5181\n",
      "Epoch 163/600\n",
      " - 24s - loss: 1.5285 - acc: 0.5214\n",
      "Epoch 164/600\n",
      " - 24s - loss: 1.5429 - acc: 0.5182\n",
      "Epoch 165/600\n",
      " - 24s - loss: 1.5141 - acc: 0.5235\n",
      "Epoch 166/600\n",
      " - 24s - loss: 1.5335 - acc: 0.5203\n",
      "Epoch 167/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 24s - loss: 1.5312 - acc: 0.5211\n",
      "Epoch 168/600\n",
      " - 24s - loss: 1.5156 - acc: 0.5259\n",
      "Epoch 169/600\n",
      " - 24s - loss: 1.5240 - acc: 0.5223\n",
      "Epoch 170/600\n",
      " - 24s - loss: 1.5110 - acc: 0.5268\n",
      "Epoch 171/600\n",
      " - 24s - loss: 1.5239 - acc: 0.5228\n",
      "Epoch 172/600\n",
      " - 24s - loss: 1.5149 - acc: 0.5250\n",
      "Epoch 173/600\n",
      " - 24s - loss: 1.5276 - acc: 0.5238\n",
      "Epoch 174/600\n",
      " - 24s - loss: 1.5047 - acc: 0.5258\n",
      "Epoch 175/600\n",
      " - 24s - loss: 1.5019 - acc: 0.5287\n",
      "Epoch 176/600\n",
      " - 24s - loss: 1.5148 - acc: 0.5259\n",
      "Epoch 177/600\n",
      " - 24s - loss: 1.4832 - acc: 0.5337\n",
      "Epoch 178/600\n",
      " - 24s - loss: 1.5030 - acc: 0.5302\n",
      "Epoch 179/600\n",
      " - 24s - loss: 1.4986 - acc: 0.5305\n",
      "Epoch 180/600\n",
      " - 25s - loss: 1.5084 - acc: 0.5282\n",
      "Epoch 181/600\n",
      " - 26s - loss: 1.5086 - acc: 0.5297\n",
      "Epoch 182/600\n",
      " - 25s - loss: 1.4971 - acc: 0.5328\n",
      "Epoch 183/600\n",
      " - 26s - loss: 1.4825 - acc: 0.5329\n",
      "Epoch 184/600\n",
      " - 26s - loss: 1.4848 - acc: 0.5347\n",
      "Epoch 185/600\n",
      " - 26s - loss: 1.4907 - acc: 0.5316\n",
      "Epoch 186/600\n",
      " - 26s - loss: 1.5014 - acc: 0.5293\n",
      "Epoch 187/600\n",
      " - 26s - loss: 1.4939 - acc: 0.5331\n",
      "Epoch 188/600\n",
      " - 25s - loss: 1.4820 - acc: 0.5356\n",
      "Epoch 189/600\n",
      " - 25s - loss: 1.4796 - acc: 0.5350\n",
      "Epoch 190/600\n",
      " - 26s - loss: 1.4814 - acc: 0.5367\n",
      "Epoch 191/600\n",
      " - 26s - loss: 1.4917 - acc: 0.5328\n",
      "Epoch 192/600\n",
      " - 26s - loss: 1.4634 - acc: 0.5402\n",
      "Epoch 193/600\n",
      " - 26s - loss: 1.4910 - acc: 0.5341\n",
      "Epoch 194/600\n",
      " - 25s - loss: 1.4870 - acc: 0.5367\n",
      "Epoch 195/600\n",
      " - 26s - loss: 1.4492 - acc: 0.5409\n",
      "Epoch 196/600\n",
      " - 25s - loss: 1.4798 - acc: 0.5363\n",
      "Epoch 197/600\n",
      " - 26s - loss: 1.4554 - acc: 0.5435\n",
      "Epoch 198/600\n",
      " - 25s - loss: 1.4870 - acc: 0.5353\n",
      "Epoch 199/600\n",
      " - 25s - loss: 1.4640 - acc: 0.5407\n",
      "Epoch 200/600\n",
      " - 25s - loss: 1.4708 - acc: 0.5388\n",
      "Epoch 201/600\n",
      " - 25s - loss: 1.4680 - acc: 0.5383\n",
      "Epoch 202/600\n",
      " - 25s - loss: 1.4587 - acc: 0.5423\n",
      "Epoch 203/600\n",
      " - 25s - loss: 1.4709 - acc: 0.5400\n",
      "Epoch 204/600\n",
      " - 26s - loss: 1.4625 - acc: 0.5423\n",
      "Epoch 205/600\n",
      " - 25s - loss: 1.4499 - acc: 0.5422\n",
      "Epoch 206/600\n",
      " - 25s - loss: 1.4614 - acc: 0.5413\n",
      "Epoch 207/600\n",
      " - 26s - loss: 1.4486 - acc: 0.5452\n",
      "Epoch 208/600\n",
      " - 25s - loss: 1.4717 - acc: 0.5382\n",
      "Epoch 209/600\n",
      " - 26s - loss: 1.4451 - acc: 0.5470\n",
      "Epoch 210/600\n",
      " - 26s - loss: 1.4399 - acc: 0.5463\n",
      "Epoch 211/600\n",
      " - 25s - loss: 1.4461 - acc: 0.5454\n",
      "Epoch 212/600\n",
      " - 25s - loss: 1.4452 - acc: 0.5459\n",
      "Epoch 213/600\n",
      " - 25s - loss: 1.4444 - acc: 0.5463\n",
      "Epoch 214/600\n",
      " - 26s - loss: 1.4559 - acc: 0.5434\n",
      "Epoch 215/600\n",
      " - 25s - loss: 1.4476 - acc: 0.5476\n",
      "Epoch 216/600\n",
      " - 26s - loss: 1.4302 - acc: 0.5521\n",
      "Epoch 217/600\n",
      " - 25s - loss: 1.4394 - acc: 0.5490\n",
      "Epoch 218/600\n",
      " - 25s - loss: 1.4646 - acc: 0.5426\n",
      "Epoch 219/600\n",
      " - 26s - loss: 1.4261 - acc: 0.5512\n",
      "Epoch 220/600\n",
      " - 25s - loss: 1.4400 - acc: 0.5493\n",
      "Epoch 221/600\n",
      " - 25s - loss: 1.4462 - acc: 0.5462\n",
      "Epoch 222/600\n",
      " - 25s - loss: 1.4301 - acc: 0.5528\n",
      "Epoch 223/600\n",
      " - 26s - loss: 1.4416 - acc: 0.5463\n",
      "Epoch 224/600\n",
      " - 25s - loss: 1.4245 - acc: 0.5515\n",
      "Epoch 225/600\n",
      " - 25s - loss: 1.4327 - acc: 0.5520\n",
      "Epoch 226/600\n",
      " - 25s - loss: 1.4063 - acc: 0.5567\n",
      "Epoch 227/600\n",
      " - 26s - loss: 1.4270 - acc: 0.5534\n",
      "Epoch 228/600\n",
      " - 26s - loss: 1.4247 - acc: 0.5540\n",
      "Epoch 229/600\n",
      " - 25s - loss: 1.4295 - acc: 0.5522\n",
      "Epoch 230/600\n",
      " - 25s - loss: 1.4491 - acc: 0.5482\n",
      "Epoch 231/600\n",
      " - 24s - loss: 1.4323 - acc: 0.5519\n",
      "Epoch 232/600\n",
      " - 24s - loss: 1.4299 - acc: 0.5523\n",
      "Epoch 233/600\n",
      " - 24s - loss: 1.4475 - acc: 0.5498\n",
      "Epoch 234/600\n",
      " - 24s - loss: 1.4136 - acc: 0.5552\n",
      "Epoch 235/600\n",
      " - 24s - loss: 1.4186 - acc: 0.5561\n",
      "Epoch 236/600\n",
      " - 24s - loss: 1.4322 - acc: 0.5525\n",
      "Epoch 237/600\n",
      " - 24s - loss: 1.4201 - acc: 0.5572\n",
      "Epoch 238/600\n",
      " - 24s - loss: 1.4189 - acc: 0.5555\n",
      "Epoch 239/600\n",
      " - 24s - loss: 1.4254 - acc: 0.5554\n",
      "Epoch 240/600\n",
      " - 24s - loss: 1.4126 - acc: 0.5582\n",
      "Epoch 241/600\n",
      " - 24s - loss: 1.4367 - acc: 0.5527\n",
      "Epoch 242/600\n",
      " - 24s - loss: 1.4128 - acc: 0.5582\n",
      "Epoch 243/600\n",
      " - 24s - loss: 1.4182 - acc: 0.5559\n",
      "Epoch 244/600\n",
      " - 24s - loss: 1.4149 - acc: 0.5602\n",
      "Epoch 245/600\n",
      " - 24s - loss: 1.4231 - acc: 0.5537\n",
      "Epoch 246/600\n",
      " - 24s - loss: 1.4068 - acc: 0.5601\n",
      "Epoch 247/600\n",
      " - 24s - loss: 1.4170 - acc: 0.5564\n",
      "Epoch 248/600\n",
      " - 24s - loss: 1.4168 - acc: 0.5564\n",
      "Epoch 249/600\n",
      " - 24s - loss: 1.4080 - acc: 0.5611\n",
      "Epoch 250/600\n",
      " - 24s - loss: 1.4185 - acc: 0.5560\n",
      "Epoch 251/600\n",
      " - 24s - loss: 1.3998 - acc: 0.5605\n",
      "Epoch 252/600\n",
      " - 24s - loss: 1.4027 - acc: 0.5616\n",
      "Epoch 253/600\n",
      " - 24s - loss: 1.4170 - acc: 0.5574\n",
      "Epoch 254/600\n",
      " - 24s - loss: 1.4121 - acc: 0.5599\n",
      "Epoch 255/600\n",
      " - 24s - loss: 1.4147 - acc: 0.5592\n",
      "Epoch 256/600\n",
      " - 24s - loss: 1.4078 - acc: 0.5604\n",
      "Epoch 257/600\n",
      " - 24s - loss: 1.3862 - acc: 0.5662\n",
      "Epoch 258/600\n",
      " - 24s - loss: 1.4062 - acc: 0.5595\n",
      "Epoch 259/600\n",
      " - 24s - loss: 1.4021 - acc: 0.5621\n",
      "Epoch 260/600\n",
      " - 24s - loss: 1.4066 - acc: 0.5589\n",
      "Epoch 261/600\n",
      " - 24s - loss: 1.4206 - acc: 0.5565\n",
      "Epoch 262/600\n",
      " - 24s - loss: 1.3998 - acc: 0.5650\n",
      "Epoch 263/600\n",
      " - 24s - loss: 1.3951 - acc: 0.5627\n",
      "Epoch 264/600\n",
      " - 24s - loss: 1.4022 - acc: 0.5626\n",
      "Epoch 265/600\n",
      " - 24s - loss: 1.4139 - acc: 0.5584\n",
      "Epoch 266/600\n",
      " - 24s - loss: 1.3978 - acc: 0.5639\n",
      "Epoch 267/600\n",
      " - 24s - loss: 1.3917 - acc: 0.5627\n",
      "Epoch 268/600\n",
      " - 24s - loss: 1.3996 - acc: 0.5622\n",
      "Epoch 269/600\n",
      " - 24s - loss: 1.4000 - acc: 0.5639\n",
      "Epoch 270/600\n",
      " - 24s - loss: 1.4078 - acc: 0.5622\n",
      "Epoch 271/600\n",
      " - 24s - loss: 1.3991 - acc: 0.5608\n",
      "Epoch 272/600\n",
      " - 24s - loss: 1.3849 - acc: 0.5642\n",
      "Epoch 273/600\n",
      " - 24s - loss: 1.4097 - acc: 0.5630\n",
      "Epoch 274/600\n",
      " - 24s - loss: 1.3672 - acc: 0.5702\n",
      "Epoch 275/600\n",
      " - 24s - loss: 1.4171 - acc: 0.5599\n",
      "Epoch 276/600\n",
      " - 24s - loss: 1.3804 - acc: 0.5668\n",
      "Epoch 277/600\n",
      " - 25s - loss: 1.3966 - acc: 0.5644\n",
      "Epoch 278/600\n",
      " - 24s - loss: 1.3808 - acc: 0.5674\n",
      "Epoch 279/600\n",
      " - 24s - loss: 1.4031 - acc: 0.5629\n",
      "Epoch 280/600\n",
      " - 24s - loss: 1.3667 - acc: 0.5690\n",
      "Epoch 281/600\n",
      " - 24s - loss: 1.3753 - acc: 0.5677\n",
      "Epoch 282/600\n",
      " - 24s - loss: 1.3865 - acc: 0.5658\n",
      "Epoch 283/600\n",
      " - 24s - loss: 1.3566 - acc: 0.5739\n",
      "Epoch 284/600\n",
      " - 24s - loss: 1.3843 - acc: 0.5673\n",
      "Epoch 285/600\n",
      " - 24s - loss: 1.3702 - acc: 0.5705\n",
      "Epoch 286/600\n",
      " - 24s - loss: 1.3709 - acc: 0.5686\n",
      "Epoch 287/600\n",
      " - 24s - loss: 1.3983 - acc: 0.5648\n",
      "Epoch 288/600\n",
      " - 24s - loss: 1.3874 - acc: 0.5690\n",
      "Epoch 289/600\n",
      " - 24s - loss: 1.3769 - acc: 0.5710\n",
      "Epoch 290/600\n",
      " - 24s - loss: 1.3629 - acc: 0.5717\n",
      "Epoch 291/600\n",
      " - 24s - loss: 1.3812 - acc: 0.5684\n",
      "Epoch 292/600\n",
      " - 24s - loss: 1.3517 - acc: 0.5761\n",
      "Epoch 293/600\n",
      " - 24s - loss: 1.3760 - acc: 0.5702\n",
      "Epoch 294/600\n",
      " - 24s - loss: 1.3977 - acc: 0.5661\n",
      "Epoch 295/600\n",
      " - 24s - loss: 1.3586 - acc: 0.5751\n",
      "Epoch 296/600\n",
      " - 24s - loss: 1.4218 - acc: 0.5619\n",
      "Epoch 297/600\n",
      " - 24s - loss: 1.3895 - acc: 0.5674\n",
      "Epoch 298/600\n",
      " - 24s - loss: 1.3597 - acc: 0.5749\n",
      "Epoch 299/600\n",
      " - 24s - loss: 1.3758 - acc: 0.5709\n",
      "Epoch 300/600\n",
      " - 24s - loss: 1.3779 - acc: 0.5728\n",
      "Epoch 301/600\n",
      " - 24s - loss: 1.3877 - acc: 0.5688\n",
      "Epoch 302/600\n",
      " - 24s - loss: 1.3591 - acc: 0.5734\n",
      "Epoch 303/600\n",
      " - 24s - loss: 1.3618 - acc: 0.5731\n",
      "Epoch 304/600\n",
      " - 24s - loss: 1.3772 - acc: 0.5719\n",
      "Epoch 305/600\n",
      " - 24s - loss: 1.3356 - acc: 0.5802\n",
      "Epoch 306/600\n",
      " - 24s - loss: 1.4010 - acc: 0.5665\n",
      "Epoch 307/600\n",
      " - 24s - loss: 1.3549 - acc: 0.5748\n",
      "Epoch 308/600\n",
      " - 24s - loss: 1.3722 - acc: 0.5710\n",
      "Epoch 309/600\n",
      " - 24s - loss: 1.3726 - acc: 0.5724\n",
      "Epoch 310/600\n",
      " - 24s - loss: 1.3790 - acc: 0.5694\n",
      "Epoch 311/600\n",
      " - 24s - loss: 1.3449 - acc: 0.5758\n",
      "Epoch 312/600\n",
      " - 24s - loss: 1.3657 - acc: 0.5728\n",
      "Epoch 313/600\n",
      " - 24s - loss: 1.3710 - acc: 0.5744\n",
      "Epoch 314/600\n",
      " - 24s - loss: 1.3933 - acc: 0.5681\n",
      "Epoch 315/600\n",
      " - 24s - loss: 1.3739 - acc: 0.5734\n",
      "Epoch 316/600\n",
      " - 24s - loss: 1.3765 - acc: 0.5730\n",
      "Epoch 317/600\n",
      " - 24s - loss: 1.3291 - acc: 0.5818\n",
      "Epoch 318/600\n",
      " - 24s - loss: 1.3940 - acc: 0.5688\n",
      "Epoch 319/600\n",
      " - 24s - loss: 1.3787 - acc: 0.5724\n",
      "Epoch 320/600\n",
      " - 24s - loss: 1.3676 - acc: 0.5738\n",
      "Epoch 321/600\n",
      " - 24s - loss: 1.3353 - acc: 0.5822\n",
      "Epoch 322/600\n",
      " - 24s - loss: 1.3854 - acc: 0.5722\n",
      "Epoch 323/600\n",
      " - 24s - loss: 1.3542 - acc: 0.5776\n",
      "Epoch 324/600\n",
      " - 24s - loss: 1.3904 - acc: 0.5708\n",
      "Epoch 325/600\n",
      " - 24s - loss: 1.3434 - acc: 0.5797\n",
      "Epoch 326/600\n",
      " - 24s - loss: 1.3669 - acc: 0.5746\n",
      "Epoch 327/600\n",
      " - 24s - loss: 1.3465 - acc: 0.5795\n",
      "Epoch 328/600\n",
      " - 24s - loss: 1.3972 - acc: 0.5714\n",
      "Epoch 329/600\n",
      " - 24s - loss: 1.3654 - acc: 0.5748\n",
      "Epoch 330/600\n",
      " - 24s - loss: 1.3890 - acc: 0.5706\n",
      "Epoch 331/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 24s - loss: 1.3673 - acc: 0.5757\n",
      "Epoch 332/600\n",
      " - 24s - loss: 1.4037 - acc: 0.5724\n",
      "Epoch 333/600\n",
      " - 24s - loss: 1.3487 - acc: 0.5803\n",
      "Epoch 334/600\n",
      " - 24s - loss: 1.3653 - acc: 0.5782\n",
      "Epoch 335/600\n",
      " - 24s - loss: 1.4090 - acc: 0.5700\n",
      "Epoch 336/600\n",
      " - 24s - loss: 1.3652 - acc: 0.5789\n",
      "Epoch 337/600\n",
      " - 24s - loss: 1.3643 - acc: 0.5766\n",
      "Epoch 338/600\n",
      " - 24s - loss: 1.3918 - acc: 0.5710\n",
      "Epoch 339/600\n",
      " - 24s - loss: 1.3633 - acc: 0.5793\n",
      "Epoch 340/600\n",
      " - 24s - loss: 1.3647 - acc: 0.5770\n",
      "Epoch 341/600\n",
      " - 24s - loss: 1.3786 - acc: 0.5735\n",
      "Epoch 342/600\n",
      " - 24s - loss: 1.3409 - acc: 0.5800\n",
      "Epoch 343/600\n",
      " - 24s - loss: 1.3776 - acc: 0.5748\n",
      "Epoch 344/600\n",
      " - 24s - loss: 1.3662 - acc: 0.5771\n",
      "Epoch 345/600\n",
      " - 24s - loss: 1.3824 - acc: 0.5743\n",
      "Epoch 346/600\n",
      " - 24s - loss: 1.3498 - acc: 0.5821\n",
      "Epoch 347/600\n",
      " - 24s - loss: 1.3776 - acc: 0.5763\n",
      "Epoch 348/600\n",
      " - 24s - loss: 1.3579 - acc: 0.5829\n",
      "Epoch 349/600\n",
      " - 24s - loss: 1.3675 - acc: 0.5756\n",
      "Epoch 350/600\n",
      " - 24s - loss: 1.3790 - acc: 0.5749\n",
      "Epoch 351/600\n",
      " - 24s - loss: 1.3411 - acc: 0.5827\n",
      "Epoch 352/600\n",
      " - 24s - loss: 1.4006 - acc: 0.5729\n",
      "Epoch 353/600\n",
      " - 24s - loss: 1.3605 - acc: 0.5779\n",
      "Epoch 354/600\n",
      " - 24s - loss: 1.3747 - acc: 0.5750\n",
      "Epoch 355/600\n",
      " - 24s - loss: 1.3416 - acc: 0.5830\n",
      "Epoch 356/600\n",
      " - 24s - loss: 1.3692 - acc: 0.5786\n",
      "Epoch 357/600\n",
      " - 24s - loss: 1.3568 - acc: 0.5802\n",
      "Epoch 358/600\n",
      " - 24s - loss: 1.3601 - acc: 0.5794\n",
      "Epoch 359/600\n",
      " - 24s - loss: 1.3356 - acc: 0.5861\n",
      "Epoch 360/600\n",
      " - 24s - loss: 1.3756 - acc: 0.5757\n",
      "Epoch 361/600\n",
      " - 24s - loss: 1.3665 - acc: 0.5778\n",
      "Epoch 362/600\n",
      " - 24s - loss: 1.3412 - acc: 0.5824\n",
      "Epoch 363/600\n",
      " - 24s - loss: 1.3722 - acc: 0.5787\n",
      "Epoch 364/600\n",
      " - 24s - loss: 1.3803 - acc: 0.5768\n",
      "Epoch 365/600\n",
      " - 24s - loss: 1.3250 - acc: 0.5885\n",
      "Epoch 366/600\n",
      " - 24s - loss: 1.3544 - acc: 0.5812\n",
      "Epoch 367/600\n",
      " - 24s - loss: 1.3879 - acc: 0.5730\n",
      "Epoch 368/600\n",
      " - 24s - loss: 1.3692 - acc: 0.5806\n",
      "Epoch 369/600\n",
      " - 24s - loss: 1.3889 - acc: 0.5753\n",
      "Epoch 370/600\n",
      " - 24s - loss: 1.3657 - acc: 0.5793\n",
      "Epoch 371/600\n",
      " - 24s - loss: 1.3826 - acc: 0.5784\n",
      "Epoch 372/600\n",
      " - 24s - loss: 1.3532 - acc: 0.5831\n",
      "Epoch 373/600\n",
      " - 24s - loss: 1.3783 - acc: 0.5753\n",
      "Epoch 374/600\n",
      " - 24s - loss: 1.3918 - acc: 0.5759\n",
      "Epoch 375/600\n",
      " - 24s - loss: 1.3396 - acc: 0.5861\n",
      "Epoch 376/600\n",
      " - 24s - loss: 1.3850 - acc: 0.5772\n",
      "Epoch 377/600\n",
      " - 24s - loss: 1.3722 - acc: 0.5815\n",
      "Epoch 378/600\n",
      " - 24s - loss: 1.3657 - acc: 0.5801\n",
      "Epoch 379/600\n",
      " - 24s - loss: 1.3291 - acc: 0.5877\n",
      "Epoch 380/600\n",
      " - 24s - loss: 1.3550 - acc: 0.5818\n",
      "Epoch 381/600\n",
      " - 24s - loss: 1.4264 - acc: 0.5679\n",
      "Epoch 382/600\n",
      " - 24s - loss: 1.3579 - acc: 0.5798\n",
      "Epoch 383/600\n",
      " - 24s - loss: 1.3492 - acc: 0.5861\n",
      "Epoch 384/600\n",
      " - 24s - loss: 1.3635 - acc: 0.5802\n",
      "Epoch 385/600\n",
      " - 24s - loss: 1.3269 - acc: 0.5856\n",
      "Epoch 386/600\n",
      " - 24s - loss: 1.3705 - acc: 0.5794\n",
      "Epoch 387/600\n",
      " - 24s - loss: 1.3480 - acc: 0.5846\n",
      "Epoch 388/600\n",
      " - 24s - loss: 1.4072 - acc: 0.5736\n",
      "Epoch 389/600\n",
      " - 24s - loss: 1.3479 - acc: 0.5826\n",
      "Epoch 390/600\n",
      " - 24s - loss: 1.3555 - acc: 0.5817\n",
      "Epoch 391/600\n",
      " - 24s - loss: 1.3678 - acc: 0.5795\n",
      "Epoch 392/600\n",
      " - 24s - loss: 1.3455 - acc: 0.5852\n",
      "Epoch 393/600\n",
      " - 24s - loss: 1.3786 - acc: 0.5784\n",
      "Epoch 394/600\n",
      " - 24s - loss: 1.3506 - acc: 0.5846\n",
      "Epoch 395/600\n",
      " - 24s - loss: 1.3626 - acc: 0.5808\n",
      "Epoch 396/600\n",
      " - 24s - loss: 1.3807 - acc: 0.5760\n",
      "Epoch 397/600\n",
      " - 24s - loss: 1.3479 - acc: 0.5845\n",
      "Epoch 398/600\n",
      " - 24s - loss: 1.3741 - acc: 0.5782\n",
      "Epoch 399/600\n",
      " - 24s - loss: 1.3456 - acc: 0.5851\n",
      "Epoch 400/600\n",
      " - 24s - loss: 1.3620 - acc: 0.5814\n",
      "Epoch 401/600\n",
      " - 24s - loss: 1.3591 - acc: 0.5819\n",
      "Epoch 402/600\n",
      " - 24s - loss: 1.3821 - acc: 0.5787\n",
      "Epoch 403/600\n",
      " - 24s - loss: 1.3610 - acc: 0.5801\n",
      "Epoch 404/600\n",
      " - 24s - loss: 1.3875 - acc: 0.5781\n",
      "Epoch 405/600\n",
      " - 24s - loss: 1.3150 - acc: 0.5909\n",
      "Epoch 406/600\n",
      " - 24s - loss: 1.3973 - acc: 0.5764\n",
      "Epoch 407/600\n",
      " - 24s - loss: 1.3457 - acc: 0.5876\n",
      "Epoch 408/600\n",
      " - 24s - loss: 1.3975 - acc: 0.5745\n",
      "Epoch 409/600\n",
      " - 24s - loss: 1.3620 - acc: 0.5821\n",
      "Epoch 410/600\n",
      " - 24s - loss: 1.3433 - acc: 0.5876\n",
      "Epoch 411/600\n",
      " - 24s - loss: 1.3647 - acc: 0.5824\n",
      "Epoch 412/600\n",
      " - 24s - loss: 1.3412 - acc: 0.5897\n",
      "Epoch 413/600\n",
      " - 24s - loss: 1.3737 - acc: 0.5794\n",
      "Epoch 414/600\n",
      " - 24s - loss: 1.3652 - acc: 0.5835\n",
      "Epoch 415/600\n",
      " - 24s - loss: 1.3253 - acc: 0.5906\n",
      "Epoch 416/600\n",
      " - 24s - loss: 1.3713 - acc: 0.5819\n",
      "Epoch 417/600\n",
      " - 24s - loss: 1.3604 - acc: 0.5825\n",
      "Epoch 418/600\n",
      " - 24s - loss: 1.3264 - acc: 0.5878\n",
      "Epoch 419/600\n",
      " - 24s - loss: 1.3847 - acc: 0.5789\n",
      "Epoch 420/600\n",
      " - 24s - loss: 1.3894 - acc: 0.5791\n",
      "Epoch 421/600\n",
      " - 24s - loss: 1.3574 - acc: 0.5849\n",
      "Epoch 422/600\n",
      " - 24s - loss: 1.3700 - acc: 0.5831\n",
      "Epoch 423/600\n",
      " - 24s - loss: 1.3753 - acc: 0.5804\n",
      "Epoch 424/600\n",
      " - 24s - loss: 1.3568 - acc: 0.5838\n",
      "Epoch 425/600\n",
      " - 24s - loss: 1.3886 - acc: 0.5783\n",
      "Epoch 426/600\n",
      " - 24s - loss: 1.3803 - acc: 0.5782\n",
      "Epoch 427/600\n",
      " - 25s - loss: 1.3455 - acc: 0.5848\n",
      "Epoch 428/600\n",
      " - 24s - loss: 1.3731 - acc: 0.5816\n",
      "Epoch 429/600\n",
      " - 24s - loss: 1.3624 - acc: 0.5842\n",
      "Epoch 430/600\n",
      " - 24s - loss: 1.3744 - acc: 0.5811\n",
      "Epoch 431/600\n",
      " - 24s - loss: 1.3700 - acc: 0.5829\n",
      "Epoch 432/600\n",
      " - 24s - loss: 1.3703 - acc: 0.5829\n",
      "Epoch 433/600\n",
      " - 24s - loss: 1.3265 - acc: 0.5900\n",
      "Epoch 434/600\n",
      " - 24s - loss: 1.3694 - acc: 0.5801\n",
      "Epoch 435/600\n",
      " - 24s - loss: 1.4137 - acc: 0.5744\n",
      "Epoch 436/600\n",
      " - 24s - loss: 1.3697 - acc: 0.5844\n",
      "Epoch 437/600\n",
      " - 24s - loss: 1.3587 - acc: 0.5830\n",
      "Epoch 438/600\n",
      " - 24s - loss: 1.3357 - acc: 0.5913\n",
      "Epoch 439/600\n",
      " - 24s - loss: 1.3298 - acc: 0.5910\n",
      "Epoch 440/600\n",
      " - 24s - loss: 1.3391 - acc: 0.5874\n",
      "Epoch 441/600\n",
      " - 24s - loss: 1.3746 - acc: 0.5832\n",
      "Epoch 442/600\n",
      " - 24s - loss: 1.3924 - acc: 0.5774\n",
      "Epoch 443/600\n",
      " - 24s - loss: 1.3567 - acc: 0.5860\n",
      "Epoch 444/600\n",
      " - 24s - loss: 1.3678 - acc: 0.5851\n",
      "Epoch 445/600\n",
      " - 24s - loss: 1.3638 - acc: 0.5840\n",
      "Epoch 446/600\n",
      " - 24s - loss: 1.3770 - acc: 0.5842\n",
      "Epoch 447/600\n",
      " - 24s - loss: 1.3572 - acc: 0.5870\n",
      "Epoch 448/600\n",
      " - 24s - loss: 1.3576 - acc: 0.5845\n",
      "Epoch 449/600\n",
      " - 24s - loss: 1.3833 - acc: 0.5820\n",
      "Epoch 450/600\n",
      " - 24s - loss: 1.3719 - acc: 0.5826\n",
      "Epoch 451/600\n",
      " - 24s - loss: 1.3742 - acc: 0.5828\n",
      "Epoch 452/600\n",
      " - 24s - loss: 1.3547 - acc: 0.5853\n",
      "Epoch 453/600\n",
      " - 24s - loss: 1.3806 - acc: 0.5806\n",
      "Epoch 454/600\n",
      " - 24s - loss: 1.3435 - acc: 0.5883\n",
      "Epoch 455/600\n",
      " - 24s - loss: 1.3989 - acc: 0.5790\n",
      "Epoch 456/600\n",
      " - 24s - loss: 1.3213 - acc: 0.5923\n",
      "Epoch 457/600\n",
      " - 24s - loss: 1.3588 - acc: 0.5845\n",
      "Epoch 458/600\n",
      " - 24s - loss: 1.4064 - acc: 0.5784\n",
      "Epoch 459/600\n",
      " - 24s - loss: 1.3322 - acc: 0.5917\n",
      "Epoch 460/600\n",
      " - 24s - loss: 1.3724 - acc: 0.5836\n",
      "Epoch 461/600\n",
      " - 24s - loss: 1.3847 - acc: 0.5822\n",
      "Epoch 462/600\n",
      " - 24s - loss: 1.3877 - acc: 0.5822\n",
      "Epoch 463/600\n",
      " - 24s - loss: 1.3363 - acc: 0.5920\n",
      "Epoch 464/600\n",
      " - 24s - loss: 1.3894 - acc: 0.5825\n",
      "Epoch 465/600\n",
      " - 24s - loss: 1.3600 - acc: 0.5874\n",
      "Epoch 466/600\n",
      " - 24s - loss: 1.3804 - acc: 0.5820\n",
      "Epoch 467/600\n",
      " - 24s - loss: 1.3677 - acc: 0.5841\n",
      "Epoch 468/600\n",
      " - 24s - loss: 1.3938 - acc: 0.5801\n",
      "Epoch 469/600\n",
      " - 24s - loss: 1.3427 - acc: 0.5911\n",
      "Epoch 470/600\n",
      " - 24s - loss: 1.3538 - acc: 0.5886\n",
      "Epoch 471/600\n",
      " - 24s - loss: 1.3728 - acc: 0.5861\n",
      "Epoch 472/600\n",
      " - 24s - loss: 1.4274 - acc: 0.5755\n",
      "Epoch 473/600\n",
      " - 24s - loss: 1.3401 - acc: 0.5928\n",
      "Epoch 474/600\n",
      " - 24s - loss: 1.3997 - acc: 0.5804\n",
      "Epoch 475/600\n",
      " - 24s - loss: 1.3847 - acc: 0.5812\n",
      "Epoch 476/600\n",
      " - 24s - loss: 1.4054 - acc: 0.5770\n",
      "Epoch 477/600\n",
      " - 24s - loss: 1.3280 - acc: 0.5916\n",
      "Epoch 478/600\n",
      " - 24s - loss: 1.3844 - acc: 0.5813\n",
      "Epoch 479/600\n",
      " - 24s - loss: 1.3736 - acc: 0.5856\n",
      "Epoch 480/600\n",
      " - 24s - loss: 1.3875 - acc: 0.5834\n",
      "Epoch 481/600\n",
      " - 24s - loss: 1.3792 - acc: 0.5844\n",
      "Epoch 482/600\n",
      " - 24s - loss: 1.3644 - acc: 0.5848\n",
      "Epoch 483/600\n",
      " - 24s - loss: 1.3929 - acc: 0.5810\n",
      "Epoch 484/600\n",
      " - 24s - loss: 1.3480 - acc: 0.5914\n",
      "Epoch 485/600\n",
      " - 24s - loss: 1.3620 - acc: 0.5855\n",
      "Epoch 486/600\n",
      " - 24s - loss: 1.4044 - acc: 0.5783\n",
      "Epoch 487/600\n",
      " - 24s - loss: 1.3746 - acc: 0.5858\n",
      "Epoch 488/600\n",
      " - 24s - loss: 1.3734 - acc: 0.5859\n",
      "Epoch 489/600\n",
      " - 24s - loss: 1.3822 - acc: 0.5841\n",
      "Epoch 490/600\n",
      " - 25s - loss: 1.4075 - acc: 0.5813\n",
      "Epoch 491/600\n",
      " - 24s - loss: 1.4078 - acc: 0.5776\n",
      "Epoch 492/600\n",
      " - 24s - loss: 1.3806 - acc: 0.5853\n",
      "Epoch 493/600\n",
      " - 24s - loss: 1.3825 - acc: 0.5834\n",
      "Epoch 494/600\n",
      " - 24s - loss: 1.4004 - acc: 0.5816\n",
      "Epoch 495/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 24s - loss: 1.3582 - acc: 0.5862\n",
      "Epoch 496/600\n",
      " - 24s - loss: 1.3620 - acc: 0.5853\n",
      "Epoch 497/600\n",
      " - 24s - loss: 1.3788 - acc: 0.5824\n",
      "Epoch 498/600\n",
      " - 24s - loss: 1.4010 - acc: 0.5795\n",
      "Epoch 499/600\n",
      " - 24s - loss: 1.4126 - acc: 0.5778\n",
      "Epoch 500/600\n",
      " - 24s - loss: 1.4004 - acc: 0.5796\n",
      "Epoch 501/600\n",
      " - 24s - loss: 1.3920 - acc: 0.5813\n",
      "Epoch 502/600\n",
      " - 24s - loss: 1.4038 - acc: 0.5800\n",
      "Epoch 503/600\n",
      " - 24s - loss: 1.3529 - acc: 0.5899\n",
      "Epoch 504/600\n",
      " - 24s - loss: 1.3584 - acc: 0.5908\n",
      "Epoch 505/600\n",
      " - 24s - loss: 1.3888 - acc: 0.5828\n",
      "Epoch 506/600\n",
      " - 24s - loss: 1.3937 - acc: 0.5797\n",
      "Epoch 507/600\n",
      " - 24s - loss: 1.3976 - acc: 0.5808\n",
      "Epoch 508/600\n",
      " - 24s - loss: 1.3853 - acc: 0.5832\n",
      "Epoch 509/600\n",
      " - 24s - loss: 1.3549 - acc: 0.5884\n",
      "Epoch 510/600\n",
      " - 24s - loss: 1.4386 - acc: 0.5720\n",
      "Epoch 511/600\n",
      " - 24s - loss: 1.3974 - acc: 0.5825\n",
      "Epoch 512/600\n",
      " - 24s - loss: 1.4055 - acc: 0.5820\n",
      "Epoch 513/600\n",
      " - 24s - loss: 1.3741 - acc: 0.5862\n",
      "Epoch 514/600\n",
      " - 24s - loss: 1.3710 - acc: 0.5860\n",
      "Epoch 515/600\n",
      " - 24s - loss: 1.4108 - acc: 0.5798\n",
      "Epoch 516/600\n",
      " - 24s - loss: 1.3825 - acc: 0.5848\n",
      "Epoch 517/600\n",
      " - 24s - loss: 1.3720 - acc: 0.5855\n",
      "Epoch 518/600\n",
      " - 24s - loss: 1.3741 - acc: 0.5851\n",
      "Epoch 519/600\n",
      " - 24s - loss: 1.4126 - acc: 0.5785\n",
      "Epoch 520/600\n",
      " - 24s - loss: 1.4400 - acc: 0.5739\n",
      "Epoch 521/600\n",
      " - 24s - loss: 1.3862 - acc: 0.5849\n",
      "Epoch 522/600\n",
      " - 24s - loss: 1.3680 - acc: 0.5862\n",
      "Epoch 523/600\n",
      " - 24s - loss: 1.3581 - acc: 0.5884\n",
      "Epoch 524/600\n",
      " - 24s - loss: 1.3872 - acc: 0.5834\n",
      "Epoch 525/600\n",
      " - 24s - loss: 1.3796 - acc: 0.5835\n",
      "Epoch 526/600\n",
      " - 24s - loss: 1.4055 - acc: 0.5786\n",
      "Epoch 527/600\n",
      " - 24s - loss: 1.4060 - acc: 0.5797\n",
      "Epoch 528/600\n",
      " - 24s - loss: 1.3680 - acc: 0.5885\n",
      "Epoch 529/600\n",
      " - 24s - loss: 1.3844 - acc: 0.5835\n",
      "Epoch 530/600\n",
      " - 24s - loss: 1.3804 - acc: 0.5850\n",
      "Epoch 531/600\n",
      " - 24s - loss: 1.4259 - acc: 0.5769\n",
      "Epoch 532/600\n",
      " - 24s - loss: 1.3859 - acc: 0.5842\n",
      "Epoch 533/600\n",
      " - 24s - loss: 1.3509 - acc: 0.5906\n",
      "Epoch 534/600\n",
      " - 24s - loss: 1.3747 - acc: 0.5843\n",
      "Epoch 535/600\n",
      " - 24s - loss: 1.4330 - acc: 0.5732\n",
      "Epoch 536/600\n",
      " - 24s - loss: 1.4149 - acc: 0.5801\n",
      "Epoch 537/600\n",
      " - 24s - loss: 1.3708 - acc: 0.5844\n",
      "Epoch 538/600\n",
      " - 24s - loss: 1.4498 - acc: 0.5734\n",
      "Epoch 539/600\n",
      " - 24s - loss: 1.3830 - acc: 0.5864\n",
      "Epoch 540/600\n",
      " - 24s - loss: 1.3728 - acc: 0.5853\n",
      "Epoch 541/600\n",
      " - 24s - loss: 1.4131 - acc: 0.5801\n",
      "Epoch 542/600\n",
      " - 24s - loss: 1.4051 - acc: 0.5807\n",
      "Epoch 543/600\n",
      " - 24s - loss: 1.3450 - acc: 0.5905\n",
      "Epoch 544/600\n",
      " - 24s - loss: 1.4236 - acc: 0.5757\n",
      "Epoch 545/600\n",
      " - 24s - loss: 1.4328 - acc: 0.5751\n",
      "Epoch 546/600\n",
      " - 24s - loss: 1.3573 - acc: 0.5880\n",
      "Epoch 547/600\n",
      " - 24s - loss: 1.4045 - acc: 0.5812\n",
      "Epoch 548/600\n",
      " - 24s - loss: 1.4055 - acc: 0.5811\n",
      "Epoch 549/600\n",
      " - 24s - loss: 1.4716 - acc: 0.5670\n",
      "Epoch 550/600\n",
      " - 24s - loss: 1.4358 - acc: 0.5724\n",
      "Epoch 551/600\n",
      " - 24s - loss: 1.3604 - acc: 0.5900\n",
      "Epoch 552/600\n",
      " - 24s - loss: 1.4528 - acc: 0.5710\n",
      "Epoch 553/600\n",
      " - 24s - loss: 1.4282 - acc: 0.5794\n",
      "Epoch 554/600\n",
      " - 24s - loss: 1.3833 - acc: 0.5870\n",
      "Epoch 555/600\n",
      " - 24s - loss: 1.4694 - acc: 0.5697\n",
      "Epoch 556/600\n",
      " - 24s - loss: 1.3634 - acc: 0.5871\n",
      "Epoch 557/600\n",
      " - 24s - loss: 1.4086 - acc: 0.5809\n",
      "Epoch 558/600\n",
      " - 24s - loss: 1.4466 - acc: 0.5722\n",
      "Epoch 559/600\n",
      " - 24s - loss: 1.3707 - acc: 0.5842\n",
      "Epoch 560/600\n",
      " - 24s - loss: 1.4472 - acc: 0.5774\n",
      "Epoch 561/600\n",
      " - 24s - loss: 1.4461 - acc: 0.5728\n",
      "Epoch 562/600\n",
      " - 24s - loss: 1.4029 - acc: 0.5801\n",
      "Epoch 563/600\n",
      " - 24s - loss: 1.3603 - acc: 0.5901\n",
      "Epoch 564/600\n",
      " - 24s - loss: 1.4121 - acc: 0.5795\n",
      "Epoch 565/600\n",
      " - 24s - loss: 1.4214 - acc: 0.5771\n",
      "Epoch 566/600\n",
      " - 24s - loss: 1.4030 - acc: 0.5804\n",
      "Epoch 567/600\n",
      " - 24s - loss: 1.4108 - acc: 0.5788\n",
      "Epoch 568/600\n",
      " - 24s - loss: 1.3861 - acc: 0.5853\n",
      "Epoch 569/600\n",
      " - 24s - loss: 1.3814 - acc: 0.5838\n",
      "Epoch 570/600\n",
      " - 24s - loss: 1.4276 - acc: 0.5784\n",
      "Epoch 571/600\n",
      " - 24s - loss: 1.4129 - acc: 0.5807\n",
      "Epoch 572/600\n",
      " - 24s - loss: 1.4694 - acc: 0.5680\n",
      "Epoch 573/600\n",
      " - 24s - loss: 1.4291 - acc: 0.5756\n",
      "Epoch 574/600\n",
      " - 24s - loss: 1.4013 - acc: 0.5814\n",
      "Epoch 575/600\n",
      " - 24s - loss: 1.3913 - acc: 0.5840\n",
      "Epoch 576/600\n",
      " - 24s - loss: 1.4371 - acc: 0.5765\n",
      "Epoch 577/600\n",
      " - 24s - loss: 1.4923 - acc: 0.5641\n",
      "Epoch 578/600\n",
      " - 24s - loss: 1.4020 - acc: 0.5825\n",
      "Epoch 579/600\n",
      " - 24s - loss: 1.3837 - acc: 0.5866\n",
      "Epoch 580/600\n",
      " - 24s - loss: 1.4425 - acc: 0.5759\n",
      "Epoch 581/600\n",
      " - 24s - loss: 1.3906 - acc: 0.5822\n",
      "Epoch 582/600\n",
      " - 24s - loss: 1.4321 - acc: 0.5774\n",
      "Epoch 583/600\n",
      " - 24s - loss: 1.4400 - acc: 0.5747\n",
      "Epoch 584/600\n",
      " - 24s - loss: 1.4143 - acc: 0.5816\n",
      "Epoch 585/600\n",
      " - 24s - loss: 1.4102 - acc: 0.5783\n",
      "Epoch 586/600\n",
      " - 24s - loss: 1.3997 - acc: 0.5816\n",
      "Epoch 587/600\n",
      " - 24s - loss: 1.4098 - acc: 0.5786\n",
      "Epoch 588/600\n",
      " - 24s - loss: 1.4149 - acc: 0.5796\n",
      "Epoch 589/600\n",
      " - 24s - loss: 1.4190 - acc: 0.5791\n",
      "Epoch 590/600\n",
      " - 24s - loss: 1.3909 - acc: 0.5851\n",
      "Epoch 591/600\n",
      " - 24s - loss: 1.4563 - acc: 0.5719\n",
      "Epoch 592/600\n",
      " - 24s - loss: 1.4296 - acc: 0.5752\n",
      "Epoch 593/600\n",
      " - 24s - loss: 1.4001 - acc: 0.5790\n",
      "Epoch 594/600\n",
      " - 24s - loss: 1.4466 - acc: 0.5741\n",
      "Epoch 595/600\n",
      " - 24s - loss: 1.4564 - acc: 0.5702\n",
      "Epoch 596/600\n",
      " - 24s - loss: 1.4139 - acc: 0.5796\n",
      "Epoch 597/600\n",
      " - 24s - loss: 1.4138 - acc: 0.5824\n",
      "Epoch 598/600\n",
      " - 24s - loss: 1.4131 - acc: 0.5791\n",
      "Epoch 599/600\n",
      " - 24s - loss: 1.4094 - acc: 0.5831\n",
      "Epoch 600/600\n",
      " - 24s - loss: 1.3668 - acc: 0.5875\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x217e7818358>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#compile and fit the model\n",
    "\n",
    "model.compile(optimizer='adam', \n",
    "              loss='categorical_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "model.fit(\n",
    "    X_train_scaled,\n",
    "    y_train_categorical,\n",
    "    epochs=600,\n",
    "    shuffle=True,\n",
    "    verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normal Neural Network - Loss: 5.862837124965721, Accuracy: 0.259124878154446\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 300)               2400      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 300)               90300     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 300)               90300     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 300)               90300     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 176)               52976     \n",
      "=================================================================\n",
      "Total params: 326,276\n",
      "Trainable params: 326,276\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Quantify the trained model\n",
    "model_loss, model_accuracy = model.evaluate(X_test_scaled, y_test_categorical, verbose=2)\n",
    "print(f\"Normal Neural Network - Loss: {model_loss}, Accuracy: {model_accuracy}\")\n",
    "\n",
    "model.summary()\n",
    "\n",
    "#save the model\n",
    "model.save(\"beer_7p_all_styles.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.15728519, -0.15349761,  0.19861203, -0.45382044, -0.12585185,\n",
       "        -0.33940182, -0.45701855],\n",
       "       [-0.15093001, -0.13477928,  0.64577732,  1.15854218,  0.83074592,\n",
       "        -0.33940182,  0.25620315],\n",
       "       [-0.15637731, -0.16285678,  0.70965808, -0.31960958,  1.30527867,\n",
       "         1.64418508,  0.25620315],\n",
       "       [-0.15773914, -0.13009969, -0.52004648, -0.39656325,  0.4348835 ,\n",
       "        -0.33940182,  0.3988475 ],\n",
       "       [-0.16364038, -0.1558374 , -0.67442497,  0.34457389, -0.86317699,\n",
       "        -0.33940182, -1.17024026],\n",
       "       [-0.14775242, -0.13711907,  1.21538073,  0.35946076, -0.21791288,\n",
       "         1.64418508,  0.61281401],\n",
       "       [-0.1541076 , -0.14647824,  0.49672223, -0.2999131 , -0.59368925,\n",
       "         1.64418508,  1.18339137],\n",
       "       [-0.1627325 , -0.14647824, -0.80750988, -0.14165421,  1.18308858,\n",
       "        -0.33940182, -0.1004077 ],\n",
       "       [-0.15592337, -0.13945886, -0.03561741, -0.41419846, -0.54431107,\n",
       "        -0.33940182,  0.25620315],\n",
       "       [-0.15683125, -0.14179865, -0.08352798, -0.25090094, -0.76525753,\n",
       "        -0.33940182, -2.24007281]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_scaled[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted classes: [102  13  19  92  13  63   7  39 124 146]\n",
      "Actual Labels: [4, 67, 134, 92, 7, 147, 10, 6, 7, 169]\n"
     ]
    }
   ],
   "source": [
    "###TEST THE MODEL - THIS DOESN'T GO IN FINAL CODE\n",
    "encoded_predictions = model.predict_classes(X_test_scaled[:10])\n",
    "\n",
    "#decode the \n",
    "prediction_labels = label_encoder.inverse_transform(encoded_predictions)\n",
    "\n",
    "#print predicted vs actual\n",
    "print(f\"Predicted classes: {prediction_labels}\")\n",
    "print(f\"Actual Labels: {list(y_test[:10])}\")\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Call the saved model and run a prediction\n",
    "\n",
    "# Load the model\n",
    "from keras.models import load_model\n",
    "model = load_model(\"beer_7p_all_styles.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#tell it what to run based on user input - AJAX here?\n",
    "\n",
    "input_beer = #call user input\n",
    "\n",
    "input_beer_scaled = #how to scale our input?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#run a prediction\n",
    "# Make predictions\n",
    "\n",
    "styleID_guess = model.predict_classes(input_beer_scaled) #Instead, do we want to show the % chance of each?\n",
    "\n",
    "styleID = #translate the style ID to a style name"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
